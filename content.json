{"meta":{"title":"wzhchen's blog","subtitle":"学习、记录、分享","description":"嵌入式开发","author":"wzhchen","url":"http://wzhchen/github.io"},"pages":[{"title":"about","date":"2019-01-08T05:48:07.000Z","updated":"2019-01-08T05:48:07.472Z","comments":true,"path":"about/index.html","permalink":"http://wzhchen/github.io/about/index.html","excerpt":"","text":""},{"title":"categories","date":"2018-01-09T05:37:54.000Z","updated":"2018-03-22T05:38:49.000Z","comments":true,"path":"categories/index.html","permalink":"http://wzhchen/github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-01-08T08:47:35.000Z","updated":"2018-03-22T05:38:49.000Z","comments":true,"path":"tags/index.html","permalink":"http://wzhchen/github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"","slug":"芯片方案/mdm9x07/QMI 拨号&网口","date":"2019-07-17T03:25:22.649Z","updated":"2019-07-21T10:50:54.508Z","comments":true,"path":"芯片方案/mdm9x07/QMI 拨号&网口/","link":"","permalink":"http://wzhchen/github.io/芯片方案/mdm9x07/QMI 拨号&网口/","excerpt":"","text":"title: QMI 拨号&amp;网口date: 2019-07-20categories: 芯片方案tags: mdm9x07 rmmnet QMI rmnet USB网口初始化 创建5控制接口misc设备，供应用层使用 function初始化rmnet_function_init —&gt; rmnet_init —&gt; gqti_ctrl_init rmnet_ctrl、rmnet_ctrl1、rmnet_ctrl2、rmnet_ctr3、dpl_ctrl 初始化USB端点 应用层：echo QTI,BAM_DMUX &gt; f_rmnet/transports frmnet_init_port，初始化网络接口设备和端口：f_rmnet、rmnet_port 控制接口类型：QTI 数据接口类型：BAM_DMUX frmnet_bind，初始化function interface 创建3个endpoint 数据TX，从机 —&gt; 主机（IN endpoint） 数据RX，主机 —&gt; 从机（OUT endpoint） 事件通知，从机 —&gt; 主机（IN endpoint） 初始接口和端点的描述 通讯方式 应用层打开/dev/rmnet_ctrl和/dev/dpl_ctrl 应用层通过/dev/rmnet_ctrl和/dev/dpl_ctrl与host端程序通讯 设置接口usb连接时，host端驱动执行USB接口设置，触发frmnet_set_alt 初始化&amp;打开事件通知端点 执行gport_rmnet_connect，连接初始化 控制通道连接初始化 数据通道连接初始化 控制通道连接初始化gsmd_ctrl_connect 初始化2个回调函数 12g_rmnet-&gt;send_encap_cmd = gqti_ctrl_send_cpkt_tomodem;g_rmnet-&gt;notify_modem = gqti_ctrl_notify_modem; 执行g_rmnet-&gt;connect(port-&gt;port_usb) —&gt; frmnet_connect 数据通道连接初始化gbam_connect 初始化&amp;打开数据TX、数据RX端点 触发gbam_connect_work 12INIT_WORK(&amp;port-&gt;connect_w, gbam_connect_work); queue_work(gbam_wq, &amp;port-&gt;connect_w); gbam_connect_work 打开bam 1ret = msm_bam_dmux_open(d-&gt;id, port, gbam_notify); 为TX和RX端口申请usb_request gbam_start_io —&gt; _gbam_start_io —&gt; gbam_alloc_requests TX和RX端点的申请大小及完成回调 12345678910111213if (in) &#123; ep = port-&gt;port_usb-&gt;in; idle = &amp;port-&gt;data_ch.tx_idle; queue_size = bam_mux_tx_q_size; ep_complete = gbam_epin_complete;&#125; else &#123; ep = port-&gt;port_usb-&gt;out; if (!ep) goto out; idle = &amp;port-&gt;data_ch.rx_idle; queue_size = bam_mux_rx_q_size; ep_complete = gbam_epout_complete;&#125; 通讯host向device发命令host驱动 —&gt; usb —&gt; device应用 使用usb的setup，由frmnet_setup处理理 命令：USB_CDC_SEND_ENCAPSULATED_COMMAND 12345678case ((USB_DIR_OUT | USB_TYPE_CLASS | USB_RECIP_INTERFACE) &lt;&lt; 8) | USB_CDC_SEND_ENCAPSULATED_COMMAND: pr_debug(\"%s: USB_CDC_SEND_ENCAPSULATED_COMMAND\\n\" , __func__); ret = w_length; req-&gt;complete = frmnet_cmd_complete; req-&gt;context = dev; break; frmnet_cmd_complete —&gt; dev-&gt;port.send_encap_cmd —&gt; gqti_ctrl_send_cpkt_tomodem 其中参数port使用ctrl_xport_num 12345678case USB_GADGET_XPORT_QTI:rmnet_port-&gt;ctrl_xport_num = no_ctrl_qti_ports;//此时ctrl_xport_num==0if (dev-&gt;port.send_encap_cmd) &#123; port_num = rmnet_ports[dev-&gt;port_num].ctrl_xport_num; dev-&gt;port.send_encap_cmd(port_num, req-&gt;buf, req-&gt;actual);&#125; gqti_ctrl_send_cpkt_tomodem 将数据放到队列中，唤醒读取的任务 12345678port = ctrl_port[portno]; //端口号为0，使用/dev/rmnet_ctrlcpkt = alloc_rmnet_ctrl_pkt(len, GFP_ATOMIC);memcpy(cpkt-&gt;buf, buf, len);cpkt-&gt;len = len;list_add_tail(&amp;cpkt-&gt;list, &amp;port-&gt;cpkt_req_q);wake_up(&amp;port-&gt;read_wq); device应用读取 qti_ctrl_read 123cpkt = list_first_entry(&amp;port-&gt;cpkt_req_q, struct rmnet_ctrl_pkt, list);ret = copy_to_user(buf, cpkt-&gt;buf, cpkt-&gt;len); device向host发命令 device应用 —&gt; usb —&gt; host驱动 qti_ctrl_write 123ret = copy_from_user(kbuf, buf, count);ret = g_rmnet-&gt;send_cpkt_response(port-&gt;port_usb, kbuf, count); 1dev-&gt;port.send_cpkt_response = frmnet_send_cpkt_response; frmnet_send_cpkt_response 123456cpkt = rmnet_alloc_ctrl_pkt(len, GFP_ATOMIC);memcpy(cpkt-&gt;buf, buf, len);cpkt-&gt;len = len;list_add_tail(&amp;cpkt-&gt;list, &amp;dev-&gt;cpkt_resp_q);//先将数据存起来frmnet_ctrl_response_available(dev);//然后通过notify端点向host发消息 host收到消息后再通过setup来取数据 1234567891011case ((USB_DIR_IN | USB_TYPE_CLASS | USB_RECIP_INTERFACE) &lt;&lt; 8) | USB_CDC_GET_ENCAPSULATED_RESPONSE: pr_debug(\"%s: USB_CDC_GET_ENCAPSULATED_RESPONSE\\n\", __func__); cpkt = list_first_entry(&amp;dev-&gt;cpkt_resp_q, struct rmnet_ctrl_pkt, list); list_del(&amp;cpkt-&gt;list); spin_unlock(&amp;dev-&gt;lock); len = min_t(unsigned, w_length, cpkt-&gt;len); memcpy(req-&gt;buf, cpkt-&gt;buf, len); host向device发数据host驱动 —&gt; usb —&gt; bam —&gt; modem host通过数据RX端点(OUT)发数据 device收到数据，执行gbam_epout_complete 1234skb_put(skb, req-&gt;actual);__skb_queue_tail(&amp;d-&gt;rx_skb_q, skb);queue_work(gbam_wq, &amp;d-&gt;write_tobam_w); 数据存放到链表，通知处理任务 1INIT_WORK(&amp;d-&gt;write_tobam_w, gbam_data_write_tobam); gbam_data_write_tobam —&gt; msm_bam_dmux_write device向host发数据modem —&gt; bam —&gt; usb —&gt; host驱动 数据通道连接初始化时open bam时设置了回调gbam_notify gbam_notify处理消息BAM_DMUX_RECEIVE 12345678switch (event) &#123;case BAM_DMUX_RECEIVE: skb = (struct sk_buff *)data; if (port) gbam_data_recv_cb(p, skb); else dev_kfree_skb_any(skb); break; gbam_data_recv_cb —&gt; gbam_write_data_tohost BAM数据收发bam支持的BAM通道非常多，USB用了其中2个 1234static unsigned bam_ch_ids[BAM_N_PORTS] = &#123; BAM_DMUX_USB_RMNET_0, BAM_DMUX_USB_DPL&#125;; 初始化时申请了2个bam端口供usb使用 1234567static int gbam_port_alloc(int portno)&#123; port = kzalloc(sizeof(struct gbam_port), GFP_KERNEL); d-&gt;id = bam_ch_ids[portno];//主要关注BAM_DMUX_USB_RMNET_0 bam_ports[portno].port = port;&#125; 发送数据gbam_data_write_tobam —&gt; msm_bam_dmux_write 123456789101112131415161718int msm_bam_dmux_write(uint32_t id, struct sk_buff *skb)&#123; //填充数据包头 hdr = (struct bam_mux_hdr *)skb_push(skb, sizeof(struct bam_mux_hdr)); /* caller should allocate for hdr and padding hdr is fine, padding is tricky */ hdr-&gt;magic_num = BAM_MUX_HDR_MAGIC_NO; hdr-&gt;cmd = BAM_MUX_HDR_CMD_DATA; hdr-&gt;signal = 0; hdr-&gt;ch_id = id; hdr-&gt;pkt_len = skb-&gt;len - sizeof(struct bam_mux_hdr); if (skb-&gt;len &amp; 0x3) skb_put(skb, 4 - (skb-&gt;len &amp; 0x3)); //使用DMA发送 pkt-&gt;skb = skb; pkt-&gt;dma_address = dma_address; pkt-&gt;is_cmd = 0;&#125; 接收数据bamr接收数据入口：__queue_rx —&gt; handle_bam_mux_cmd —&gt; bam_mux_process_data 接收的数据包中通道ID，根据通道找到notify，msm_bam_dmux_open打开通道时传入 modem 网口网口创建高通原始代码中网口名字不叫modem，面是rmnet_data kernel初始化时默认没有创建rmnet网口 rmnet创建入口：bam_rmnet_probe kernel初始化时创建了bam_dmux_ch_xx（xx表示有很多）平台驱动 启动后收到了bam数据（命令：BAM_MUX_HDR_CMD_OPEN），添加平台设备bam_dmux_ch_0 handle_bam_mux_cmd —&gt; handle_bam_mux_cmd_open —&gt; platform_device_add 触发bam_rmnet_probe 创建rmnet0网口，用于控制交互 rmnet_data创建入口： rmnet_vnd_create_dev rmnet_config_netlink_msg_handler –&gt; rmnet_create_vnd –&gt; rmnet_vnd_create_dev 创建8个网口，rmnet_data0 - rmnet_data7，用于数据收发 netmgrd初始化,将rmnet和和rmnet_data绑定 使用 RMNET_NETLINK_SET_LOGICAL_EP_CONFIG命令 _rmnet_netlink_set_logical_ep_config –&gt; rmnet_set_logical_endpoint_config 将rmnet_data0的epconfig.egress_dev指向rmnet0 打开网口数据收发需要使用bam，因此需要打开bam netmgrd进程使用ioctl打开了rmnet0网口 12345678910netmgr_kif_ifioctl_open_port (const char * dev)&#123; /* Open a datagram socket to use for issuing the ioctl */ if ((fd = socket(AF_INET, SOCK_DGRAM, 0)) &lt; 0) &#123; //此处使用的接口名为rmnet0 /* Set device name in ioctl req struct */ (void)strlcpy(ifr.ifr_name, dev, sizeof(ifr.ifr_name)); /* Get current if flags for the device */ if (ioctl(fd, RMNET_IOCTL_OPEN, &amp;ifr) &lt; 0) &#123;&#125; kernel中执行rmnet0网口的open操作 123456789101112131415static int rmnet_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)&#123; case RMNET_IOCTL_OPEN: /* Open transport port */ rc = __rmnet_open(dev); static int __rmnet_open(struct net_device *dev)&#123; int r; struct rmnet_private *p = netdev_priv(dev); if (p-&gt;device_up == DEVICE_UNINITIALIZED) &#123; r = msm_bam_dmux_open(p-&gt;ch_id, dev, bam_notify); &#125; p-&gt;device_up = DEVICE_ACTIVE; bam只打开一次，关闭接口时也不关闭bam 发送数据数据收发使用rmnet_data0接口（现已改名成modem） rmnet_data0接口的发送函数：rmnet_vnd_start_xmit 12345678910111213141516171819static netdev_tx_t rmnet_vnd_start_xmit(struct sk_buff *skb, struct net_device *dev)&#123; struct rmnet_vnd_private_s *dev_conf; trace_rmnet_vnd_start_xmit(skb); dev_conf = (struct rmnet_vnd_private_s *) netdev_priv(dev); if (dev_conf-&gt;local_ep.egress_dev) &#123; /* QoS header should come after MAP header */ if (dev_conf-&gt;qos_version) rmnet_vnd_add_qos_header(skb, dev, dev_conf-&gt;qos_version); rmnet_egress_handler(skb, &amp;dev_conf-&gt;local_ep); &#125; else &#123; dev-&gt;stats.tx_dropped++; rmnet_kfree_skb(skb, RMNET_STATS_SKBFREE_VND_NO_EGRESS); &#125; return NETDEV_TX_OK;&#125; 数据由rmnet_egress_handler处理，其中dev_conf-&gt;local_ep.egress_dev在前面有初始化 123456789void rmnet_egress_handler(struct sk_buff *skb, struct rmnet_logical_ep_conf_s *ep)&#123; struct rmnet_phys_ep_conf_s *config; struct net_device *orig_dev; int rc; orig_dev = skb-&gt;dev; skb-&gt;dev = ep-&gt;egress_dev; //替换skb的设备，此时egress_dev为rmnet0 rc = dev_queue_xmit(skb); //将skb存入rmnet0的队列中 触发rmnet0的发送队列：rmnet_xmit —&gt; _rmnet_xmit —&gt; msm_bam_dmux_write 接收数据打开bam时传入了notify函数bam_notify 123456789101112static void bam_notify(void *dev, int event, unsigned long data)&#123; switch (event) &#123; case BAM_DMUX_RECEIVE: bam_recv_notify(dev, (struct sk_buff *)(data)); static void bam_recv_notify(void *dev, struct sk_buff *skb)&#123; if (skb) &#123; skb-&gt;dev = dev; netif_rx_ni(skb); //数据包入协议栈 rmnet处理数据包：__rmnet_deliver_skb 数据包从rmnet0进入协议栈，rmnet_data0会向协议栈注册一些回调用于数据包处理，比如更新rmnet_data0的统计值：rmnet_vnd_rx_fixup， qti数据处理应用层启动了一个qti进程，负责与host端的驱动交互，同时通过/dev/smdcntl8与modem交互 qti接收host端数据host端发的数据通过/dev/rmnet_ctrl到达qti进程 数据由qti_rmnet_ph_recv_msg处理，再调用qti_rmnet_modem_send_msg处理 数据交给qti_rmnet_process_qmi_tx_to_modem处理一遍（可能会修改数据） 数据转发给/dev/smdcntl8（发给modem） 注：首次接收到数据，需要打开&amp;初始化与modem侧的通信通道，否则smdcntl8不能通信 qti接收modem数据modem发的数据通过/dev/smdcntl8到达qti进程 数据由qti_rmnet_modem_recv_msg处理 数据交给qti_rmnet_process_qmi_rx_from_modem处理一遍 qti修改某些服务的数据后再转给host端 数据转发给/dev/rmnet_ctrl（发给host） 打开通信通道qti_rmnet_ph_recv_msg —&gt; qti_rmnet_process_ph_reset 首先确认USB是否确实已经连接 12ret = ioctl(rmnet_state_config-&gt;ph_iface[PH_DRIVER_TYPE_USB].ph_iface_fd, FRMNET_CTRL_GET_LINE_STATE, &amp;line_state); 已连接且通道没有打开，则执行打开&amp;初始化 1234567891011if(line_state == 1)&#123; if(!rmnet_state_config-&gt;dtr_enabled) &#123; //向dpm服务发请求，打开DATA40_CNTL通道 ret_val = qti_rmnet_dpm_port_open(); //打开smdcntl8接口，绑定qti_rmnet_modem_recv_msg处理modem的数据 if(qti_rmnet_modem_init(rmnet_state_config, dpl_state_config) &lt; 0) rmnet_state_config-&gt;dtr_enabled = 1; 打开DATA40_CNTL通道后会触发Kernel里创建SDM设备（SDM里有描述） dpm服务的初始化 进程启动时调用了qti_dpm_init，初始化了DMP qmi客户端 QMI的初始化在QMI客户端 qmuxd进程qmuxd进程提供qmi服务 qmuxd创建/tmp/qmux_connect_socket供客户端使用linux_qmi_qmux_if_get_listener_socket linux_qmi_qmux_if_configure_ports，默认关闭了所以端口 123456/* Disabling all channels initially to enable only required channels later.*/for (i = QMI_CONN_ID_RMNET_0; i &lt; LINUX_QMI_MAX_CONN_SUPPORTED; i++)&#123; qmi_qmux_disable_port(linux_qmi_conn_id_enablement_array[i].qmi_conn_id, linux_qmi_conn_id_enablement_array[i].data_ctl_port, TRUE);&#125; 客户通过qmux_connect_socket连接qmuxd 为客户端分配一个id：qmux_client_id 将qmux_client_id发给客户端，后续客户端需要用这个id来通讯 qmuxd为客户端创建数据结构，更新linux_qmi_qmux_if_client_id_array 客户端发数据 client进程 —&gt; qmux_connect_socket —&gt; qmuxd进程 qmuxd进程使用qmux_client_id（连接时分配的）发数据，处理函数：qmi_qmux_tx_msg client发数据的消息头里包含qmi_conn_id，既数据发给谁，默认rmnet0 qmi_qmux_if_internal_use_conn_id 客户商使用qmi_qmux_if_send_to_qmux函数发数据 最终调用 使用linux_qmi_qmux_if_client_tx_msg 数据面使用qmi_qmux_if_send_qmi_msg（msg_id固定为QMI_QMUX_IF_QMI_MSG_ID） 控制面使用qmi_qmux_if_send_if_msg_to_qmux（可指定msg_id） qmuxd接收客户端的消息 main中从客户端接收数据：linux_qmi_qmux_if_server_process_client_msg 使用qmi_qmux_tx_msg转发到消息 qmuxd处理客户端数据：qmi_qmux_tx_msg 第一次需要连接：qmi_qmux_open_connection —&gt; linux_qmi_qmux_io_open_conn 因为默认所有的端口都被关闭，因此默认连接不成功 默认客户端使用rmnet0 按照客户使用的msg_id做不同分类处理 客户数据面使用QMI_QMUX_IF_QMI_MSG_ID，数据转发到modem 由qmi_qmux_tx_to_modem处理 默认使用rmnet0，对应的控制节点为/dev/smdctl0 因为端口默认是关闭的，正常数据不会被发送 qmi客户端初始化libqmiserver.so中有函数void __attribute__ ((constructor)) qmi_fw_cci_init(void)，在main函数之前就运行，添加了一些port到xport_tbl，比如： 12345qmi_cci_xport_start(&amp;qcci_ipc_router_ops, NULL);//最先添加，优先使用qmi_cci_xport_start(&amp;qmuxd_ops, (void *)QMI_CLIENT_QMUX_RMNET_INSTANCE_0);qmi_cci_xport_start(&amp;qmuxd_ops, (void *)QMI_CLIENT_QMUX_RMNET_USB_INSTANCE_0);qmi_cci_xport_start(&amp;qmuxd_ops, (void *)QMI_CLIENT_QMUX_RMNET_SMUX_INSTANCE_0);qmi_cci_xport_start(&amp;qmuxd_ops, (void *)QMI_CLIENT_QMUX_RMNET_MHI_INSTANCE_0); qmi_client_init_instance —&gt; qmi_client_get_service_instance —&gt; qmi_client_get_service_list查的服务 遍历xport_tbl表，使用lookup函数(xport_lookup)查找服务 qmi_client_init初始化客户端 xport_lookup 优先使用qcci_ipc_router_ops的xport_lookup 通过AF_MSM_IPC连接到内核 使用ioctl（命令：IPC_ROUTER_IOCTL_LOOKUP_SERVER）从内核查找服务 查找使用service（服务ID）和instance（服务版本） 内核提供的服务查看文件：/sys/kernel/debug/msm_ipc_route/dump_servers 其次使用qmuxd_ops的xport_lookup 查找之前需要边连接qmuxd 如果连接不上(qmuxd进程没有启动)则等待1分钟,尝试60次 qmuxd里关闭了接口，实际不生效，获取不到服务 注:虽然实际没使用qmuxd,但qmuxd进程不启动时会导致客户端每次请求等待1分钟 qmi_client_init 找出服务提供者，默认服务由qcci_ipc_router_ops提供 初始化客户端内部使用的clnt，细节在qmi_cci_client_alloc里 打开服务，ops-&gt;open —&gt; xport_open 保存open的返回句柄，给后续使用 xport_open 获取服务时得到一个地址addr，后续数据通讯使用这个地址 服务由qcci_ipc_router_ops，所有的操作路由到kernel，由kernel处理 初始化控制消息read线程：ctrl_msg_reader_thread 进程只有一个控消息线程 打开socket，得到到fd，给线程用 发命令IPC_ROUTER_IOCTL_BIND_CONTROL_PORT到kernel 创建线程 初始化数据消息read线程：data_msg_reader_thread 进程可以有多个数据息线程 打开socket，得到到fd，给线程用 创建线程 发送数据qmi_client_send_msg_sync 根据handle找出clnt（在qmi_cci_client_alloc中创建） 从clnt中找到xport（在qmi_client_init中添加，在qmi_client_get_service_instance中初始化) 数据编码&amp;发送：encode_and_send 使用qmi_cci_send发送数据 使用服务提供的send发送数据：xport_send 数据发给kernel（携带了服务地址） 等待数据回应：qmi_cci_response_wait_loop 数据消息read线程会通知当前线程 读取数据data_msg_reader_thread 从kernel读取数据，转发到应用程序 从kernel读取控制消息，主要用于服务通知 如果服务启动晚于应用初始化，qmi_client_init_instance 会等待服务 ipc router从名字上看是进程间通讯路由功能，实际是实现了一个sock通讯 server ipc sock core client 初始化sock_register(&amp;msm_ipc_family_ops) 注册IPC sock类型，名字为MSM_IPC 添加诊断服务诊断服务不是重点，不关注细节 kernel启动时注册了许多诊断服务：diag_socket_init —&gt; __diag_socket_init 服务地址： 12info-&gt;svc_id = DIAG_SVC_ID;info-&gt;ins_id = ins_base + ins_offset; 诊断服务的创建：socket_open_server 12345678910111213info-&gt;hdl-&gt;sk-&gt;sk_data_ready = socket_data_ready;info-&gt;hdl-&gt;sk-&gt;sk_write_space = socket_flow_cntl;srv_addr.family = AF_MSM_IPC;srv_addr.address.addrtype = MSM_IPC_ADDR_NAME;srv_addr.address.addr.port_name.service = info-&gt;svc_id;srv_addr.address.addr.port_name.instance = info-&gt;ins_id;ret = kernel_bind(info-&gt;hdl, (struct sockaddr *)&amp;srv_addr, sizeof(srv_addr));----------&gt;msm_ipc_router_bindmsm_ipc_router_register_server QMI服务注册modem 发送请求 —-&gt; linux创建服务 modem给linux发命令:IPC_ROUTER_CTRL_CMD_NEW_SERVER,linux侧添加服务 12case IPC_ROUTER_CTRL_CMD_NEW_SERVER: rc = process_new_server_msg(xprt_info, msg, pkt); 注：新建服务时使用xprt_info，后续客户端收发数据使用xprt_info-&gt;xprt提供的接口 process_new_server_msg 使用服务的ID(node_id, port_id)创建entry和port供后续查找数据结构使用 1234567rt_entry = ipc_router_get_rtentry_ref(msg-&gt;srv.node_id);if (!rt_entry) &#123; rt_entry = create_routing_table_entry(msg-&gt;srv.node_id, xprt_info);&#125;rport_ptr = ipc_router_create_rport(msg-&gt;srv.node_id, msg-&gt;srv.port_id, xprt_info); 使用服务地址(service, instance)创建服务 123server = msm_ipc_router_create_server( msg-&gt;srv.service, msg-&gt;srv.instance, msg-&gt;srv.node_id, msg-&gt;srv.port_id, xprt_info); xprt_info和modem数据如何达到linux侧的细节在后面讲 ipc route smd实现linux侧数据与共享内存设备（包含modem）数据交互，以modem举例 server(modem) ipc sock core client(应用app) 初始化msm_ipc_router_smd_xprt_init，添加平台驱动：ipc_router_smd_xprt 设备树配置 qcom,ipc_router_modem_xprt { compatible = &quot;qcom,ipc_router_smd_xprt&quot;; qcom,ch-name = &quot;IPCRTR&quot;; qcom,xprt-remote = &quot;modem&quot;; qcom,xprt-linkid = &lt;1&gt;; qcom,xprt-version = &lt;1&gt;; qcom,fragmented-data; qcom,disable-pil-loading; }; probe时初始化服务： msm_ipc_router_smd_xprt_probe —&gt; msm_ipc_router_smd_config_init 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051static int msm_ipc_router_smd_config_init( struct msm_ipc_router_smd_xprt_config *smd_xprt_config)&#123; struct msm_ipc_router_smd_xprt *smd_xprtp; smd_xprtp = kzalloc(sizeof(struct msm_ipc_router_smd_xprt), GFP_KERNEL); if (IS_ERR_OR_NULL(smd_xprtp)) &#123; IPC_RTR_ERR(\"%s: kzalloc() failed for smd_xprtp id:%s\\n\", __func__, smd_xprt_config-&gt;ch_name); return -ENOMEM; &#125; smd_xprtp-&gt;xprt.link_id = smd_xprt_config-&gt;link_id; smd_xprtp-&gt;xprt_version = smd_xprt_config-&gt;xprt_version; smd_xprtp-&gt;edge = smd_xprt_config-&gt;edge; smd_xprtp-&gt;xprt_option = smd_xprt_config-&gt;xprt_option; smd_xprtp-&gt;disable_pil_loading = smd_xprt_config-&gt;disable_pil_loading; strlcpy(smd_xprtp-&gt;ch_name, smd_xprt_config-&gt;ch_name, SMD_MAX_CH_NAME_LEN); strlcpy(smd_xprtp-&gt;xprt_name, smd_xprt_config-&gt;xprt_name, XPRT_NAME_LEN); smd_xprtp-&gt;xprt.name = smd_xprtp-&gt;xprt_name; smd_xprtp-&gt;xprt.set_version = ipc_router_smd_set_xprt_version; smd_xprtp-&gt;xprt.get_version = msm_ipc_router_smd_get_xprt_version; smd_xprtp-&gt;xprt.get_option = msm_ipc_router_smd_get_xprt_option; smd_xprtp-&gt;xprt.read_avail = NULL; smd_xprtp-&gt;xprt.read = NULL; smd_xprtp-&gt;xprt.write_avail = msm_ipc_router_smd_remote_write_avail; smd_xprtp-&gt;xprt.write = msm_ipc_router_smd_remote_write;//客户端的数据由write发给smd smd_xprtp-&gt;xprt.close = msm_ipc_router_smd_remote_close; smd_xprtp-&gt;xprt.sft_close_done = smd_xprt_sft_close_done; smd_xprtp-&gt;xprt.priv = NULL; init_waitqueue_head(&amp;smd_xprtp-&gt;write_avail_wait_q); smd_xprtp-&gt;in_pkt = NULL; smd_xprtp-&gt;is_partial_in_pkt = 0; INIT_DELAYED_WORK(&amp;smd_xprtp-&gt;read_work, smd_xprt_read_data);//从远端读取数据 spin_lock_init(&amp;smd_xprtp-&gt;ss_reset_lock); smd_xprtp-&gt;ss_reset = 0; msm_ipc_router_smd_driver_register(smd_xprtp);//注册驱动 return 0;&#125; 使用设备树里的名字IPCRTR注册平台驱动 123456789101112131415161718192021222324252627282930313233static int msm_ipc_router_smd_driver_register( struct msm_ipc_router_smd_xprt *smd_xprtp)&#123; int ret; struct msm_ipc_router_smd_xprt *item; unsigned already_registered = 0; mutex_lock(&amp;smd_remote_xprt_list_lock_lha1); list_for_each_entry(item, &amp;smd_remote_xprt_list, list) &#123; if (!strcmp(smd_xprtp-&gt;ch_name, item-&gt;ch_name)) already_registered = 1; &#125; list_add(&amp;smd_xprtp-&gt;list, &amp;smd_remote_xprt_list); mutex_unlock(&amp;smd_remote_xprt_list_lock_lha1); if (!already_registered) &#123; smd_xprtp-&gt;driver.driver.name = smd_xprtp-&gt;ch_name; smd_xprtp-&gt;driver.driver.owner = THIS_MODULE; smd_xprtp-&gt;driver.probe = msm_ipc_router_smd_remote_probe; ret = platform_driver_register(&amp;smd_xprtp-&gt;driver); if (ret) &#123; IPC_RTR_ERR( \"%s: Failed to register platform driver [%s]\\n\", __func__, smd_xprtp-&gt;ch_name); return ret; &#125; &#125; else &#123; IPC_RTR_ERR(\"%s Already driver registered %s\\n\", __func__, smd_xprtp-&gt;ch_name); &#125; return 0;&#125; 如果创建IPCRTR平台设备，触发msm_ipc_router_smd_remote_probe 123456789101112static int msm_ipc_router_smd_remote_probe(struct platform_device *pdev)&#123; smd_xprtp = find_smd_xprt_list(pdev); smd_xprtp-&gt;pil = msm_ipc_load_subsystem( smd_xprtp-&gt;edge); rc = smd_named_open_on_edge(smd_xprtp-&gt;ch_name, smd_xprtp-&gt;edge, &amp;smd_xprtp-&gt;channel, smd_xprtp, msm_ipc_router_smd_remote_notify); //modem有数据发给linux时，触发msm_ipc_router_smd_remote_notify&#125; 注意：此处需要一个IPCRTR平台设备才能触发probe，IPCRTR设备在哪里创建？ IPCRTR平台设备的创建在SDM里 QMI数据收发发送数据应用层发数据到达qcci_ipc_router_ops-&gt;xport_send，细节在qmi客户端有讲 xport_send的数据到到kernel的msm_ipc_router_sendmsg xport_send发数据时携带了服务地址，数据由kernel路由到指定的服务 msm_ipc_router_sendmsg发数据时携带源端口（包含client进程sock信息） 继续调用发送：msm_ipc_router_send_to 123456...//构造数据包pkt = create_pkt(data); ...//发送报文ret = msm_ipc_router_write_pkt(src, rport_ptr, pkt, timeout); 填充包头&amp;发送：msm_ipc_router_write_pkt 123456789101112hdr = &amp;(pkt-&gt;hdr);hdr-&gt;version = IPC_ROUTER_V1;hdr-&gt;type = IPC_ROUTER_CTRL_CMD_DATA;hdr-&gt;src_node_id = src-&gt;this_port.node_id;hdr-&gt;src_port_id = src-&gt;this_port.port_id;hdr-&gt;size = pkt-&gt;length;hdr-&gt;control_flag = 0;hdr-&gt;dst_node_id = rport_ptr-&gt;node_id;hdr-&gt;dst_port_id = rport_ptr-&gt;port_id;/*使用*/ret = xprt_info-&gt;xprt-&gt;write(pkt, pkt-&gt;length, xprt_info-&gt;xprt); 其中 xprt_info-&gt;xprt在msm_ipc_router_smd_config_init中创建，对应的write函数为 msm_ipc_router_smd_remote_write —&gt; smd_write_segment 12345int smd_write_segment(smd_channel_t *ch, const void *data, int len)&#123; bytes_written = smd_stream_write(ch, data, len, true); //其中ch在smd_alloc_channel中创建，对应的通道为IPCRTR&#125; 接收数据就用层打开IPC_MSM类型的sock，从kernel的msm_ipc_router_recvmsg接收数据 12345678910static int msm_ipc_router_recvmsg(struct kiocb *iocb, struct socket *sock, struct msghdr *m, size_t buf_len, int flags)&#123; //等待数据 ret = msm_ipc_router_rx_data_wait(port_ptr, timeout); //读取数据 ret = msm_ipc_router_read(port_ptr, &amp;pkt, buf_len); //解析数据 ret = msm_ipc_router_extract_msg(m, pkt);&#125; 读取数据，从列队中取出数据 123456int msm_ipc_router_read(struct msm_ipc_port *port_ptr, struct rr_packet **read_pkt, size_t buf_len)&#123; pkt = list_first_entry(&amp;port_ptr-&gt;port_rx_q, struct rr_packet, list);&#125; 重点是数据怎么放入队列中 123456789static void do_read_data(struct work_struct *work)&#123; post_pkt_to_port(port_ptr, pkt, 0);&#125;static int post_pkt_to_port(struct msm_ipc_port *port_ptr, struct rr_packet *pkt, int clone)&#123; list_add_tail(&amp;temp_pkt-&gt;list, &amp;port_ptr-&gt;port_rx_q);&#125; 其中do_read_data的调用在Modem发数据到Linux有详细说明 加密认证客户端发送数据之前需要配置加密认证方式，否则不能发数据 123456static int msm_ipc_router_sendmsg(struct kiocb *iocb, struct socket *sock, struct msghdr *m, size_t total_len)&#123; if (port_ptr-&gt;type == CLIENT_PORT) wait_for_irsc_completion(); //会一直等待认证配置完成&#125; 认证配置由应用层irsc_util进程负责 irsc_utilipc router转发数据之前需要配置加密，irsc_util进程负责设置配置 系统启动时执行：/usr/bin/irsc_util /etc/sec_config 默认情况不存在/etc/sec_config文件，则使用默认配置 irsc_util代码： 12345678910111213141516fd = socket(AF_MSM_IPC, SOCK_DGRAM, 0);if (!irsc_d-&gt;sec_info || !irsc_d-&gt;sec_info-&gt;num_entries) &#123; arg = calloc(1, (sizeof(*arg) + 1 * sizeof(uint32_t))); if (!arg) &#123; IRSC_ERR(\"Calloc failure, Config feeding error\\n\"); close(fd); return IRSC_NO_MEM; &#125; //没有配置，发送IPC_ROUTER_IOCTL_CONFIG_SEC_RULES命令，使用启用默认配置 if (ioctl(fd, IPC_ROUTER_IOCTL_CONFIG_SEC_RULES命令，, arg) &lt; 0) &#123; IRSC_DEBUG(\"Absent/Invalid config,Default rules apply\\n\"); &#125; free(arg); close(fd); return IRSC_INVALID_FILE;&#125; 进入到内核代码： 12345678910111213case IPC_ROUTER_IOCTL_CONFIG_SEC_RULES: ret = msm_ipc_config_sec_rules((void *)arg); if (ret != -EPERM) port_ptr-&gt;type = IRSC_PORT; break; //socket关闭时 if (port_ptr-&gt;type == IRSC_PORT) &#123; down_write(&amp;local_ports_lock_lhc2); list_del(&amp;port_ptr-&gt;list); up_write(&amp;local_ports_lock_lhc2); signal_irsc_completion(); //通知irsc完成 &#125; Modem发数据到Linuxmodem发数据给linux总体思路 数据存入共享内存 通知AP侧（linux侧）的CPU AP侧CPU收到中断 中断中处理数据：handle_smd_irq 具体数据处理函数在smd_alloc_channel注册 modem侧打开端口modem发数据之前发送打开端口命令，触发msm_ipc_router_smd_remote_notify 事件是SMD_EVENT_OPEN 1234567891011121314case SMD_EVENT_OPEN: xprt_work = kmalloc(sizeof(struct msm_ipc_router_smd_xprt_work), GFP_ATOMIC); if (!xprt_work) &#123; IPC_RTR_ERR( \"%s: Couldn't notify %d event to IPC Router\\n\", __func__, event); return; &#125; //后续数据收发使用xprt_work-&gt;xprt，即使用smd提供的xprt xprt_work-&gt;xprt = &amp;smd_xprtp-&gt;xprt; INIT_WORK(&amp;xprt_work-&gt;work, smd_xprt_open_event); queue_work(smd_xprtp-&gt;smd_xprt_wq, &amp;xprt_work-&gt;work); break; 继续执行打开 123456789101112131415161718static void smd_xprt_open_event(struct work_struct *work)&#123; struct msm_ipc_router_smd_xprt_work *xprt_work = container_of(work, struct msm_ipc_router_smd_xprt_work, work); struct msm_ipc_router_smd_xprt *smd_xprtp = container_of(xprt_work-&gt;xprt, struct msm_ipc_router_smd_xprt, xprt); unsigned long flags; spin_lock_irqsave(&amp;smd_xprtp-&gt;ss_reset_lock, flags); smd_xprtp-&gt;ss_reset = 0; spin_unlock_irqrestore(&amp;smd_xprtp-&gt;ss_reset_lock, flags); msm_ipc_router_xprt_notify(xprt_work-&gt;xprt,//后续数据收发使用xprt_work-&gt;xprt IPC_ROUTER_XPRT_EVENT_OPEN, NULL); //打开命令 D(\"%s: Notified IPC Router of %s OPEN\\n\", __func__, xprt_work-&gt;xprt-&gt;name); kfree(xprt_work);&#125; 继续打开 12345678910111213case IPC_ROUTER_XPRT_EVENT_OPEN: xprt_work = kmalloc(sizeof(struct msm_ipc_router_xprt_work), GFP_ATOMIC); if (xprt_work) &#123; xprt_work-&gt;xprt = xprt;//后续数据收发使用这个 INIT_WORK(&amp;xprt_work-&gt;work, xprt_open_worker); queue_work(msm_ipc_router_workqueue, &amp;xprt_work-&gt;work); &#125; else &#123; IPC_RTR_ERR( \"%s: malloc failure - Couldn't notify OPEN event\", __func__); &#125; break; 添加一个端口 12345678static void xprt_open_worker(struct work_struct *work)&#123; struct msm_ipc_router_xprt_work *xprt_work = container_of(work, struct msm_ipc_router_xprt_work, work); msm_ipc_router_add_xprt(xprt_work-&gt;xprt);//后续数据收发使用xprt_work-&gt;xprt kfree(xprt_work);&#125; 创建读取任务 1INIT_WORK(&amp;xprt_info-&gt;read_data, do_read_data); 接收modem数据modem有数据发给linux时，触发msm_ipc_router_smd_remote_notify 事件是SMD_EVENT_DATA 1234567case SMD_EVENT_DATA: if (smd_read_avail(smd_xprtp-&gt;channel)) queue_delayed_work(smd_xprtp-&gt;smd_xprt_wq, &amp;smd_xprtp-&gt;read_work, 0); if (smd_write_segment_avail(smd_xprtp-&gt;channel)) wake_up(&amp;smd_xprtp-&gt;write_avail_wait_q); break; 其中md_xprtp-&gt;read_work在msm_ipc_router_smd_config_init里初始化 1INIT_DELAYED_WORK(&amp;smd_xprtp-&gt;read_work, smd_xprt_read_data); smd_xprt_read_data 从modem侧读取数据包，放入队列 1234skb_queue_tail(smd_xprtp-&gt;in_pkt-&gt;pkt_fragment_q, ipc_rtr_pkt);msm_ipc_router_xprt_notify(&amp;smd_xprtp-&gt;xprt, IPC_ROUTER_XPRT_EVENT_DATA, (void *)smd_xprtp-&gt;in_pkt); 继续放入队列 1234567891011121314void msm_ipc_router_xprt_notify(struct msm_ipc_router_xprt *xprt, unsigned event, void *data)&#123; pkt = clone_pkt((struct rr_packet *)data); if (!pkt) return; mutex_lock(&amp;xprt_info-&gt;rx_lock_lhb2); list_add_tail(&amp;pkt-&gt;list, &amp;xprt_info-&gt;pkt_list); __pm_stay_awake(&amp;xprt_info-&gt;ws); mutex_unlock(&amp;xprt_info-&gt;rx_lock_lhb2); queue_work(xprt_info-&gt;workqueue, &amp;xprt_info-&gt;read_data);&#125; 唤醒读取任务，执行do_read_data 处理modem的数据do_read_data modem发过来的数据包格式 12345678910struct rr_header_v1 &#123; uint32_t version; uint32_t type; uint32_t src_node_id; uint32_t src_port_id; uint32_t control_flag; uint32_t size; uint32_t dst_node_id; uint32_t dst_port_id;&#125;; 按照不同类型创建执行不同操作，其中控制消息 1234if (hdr-&gt;type != IPC_ROUTER_CTRL_CMD_DATA) &#123; process_control_msg(xprt_info, pkt); goto read_next_pkt1;&#125; 其中包含创建服务 12345678910111213141516171819switch (msg-&gt;cmd) &#123;case IPC_ROUTER_CTRL_CMD_HELLO: rc = process_hello_msg(xprt_info, msg, hdr); break;case IPC_ROUTER_CTRL_CMD_RESUME_TX: rc = process_resume_tx_msg(msg, pkt); break;case IPC_ROUTER_CTRL_CMD_NEW_SERVER: //创建服务 rc = process_new_server_msg(xprt_info, msg, pkt); break;case IPC_ROUTER_CTRL_CMD_REMOVE_SERVER: rc = process_rmv_server_msg(xprt_info, msg, pkt); break;case IPC_ROUTER_CTRL_CMD_REMOVE_CLIENT: rc = process_rmv_client_msg(xprt_info, msg, pkt); break;default: rc = -ENOSYS;&#125; SMD共享内存设备 partitions smem_areas 初始化下表为支持了smd（共享内存设备） 12345678910111213enum &#123; SMEM_APPS, SMEM_MODEM, //modem设备 SMEM_Q6, SMEM_DSPS, SMEM_WCNSS, SMEM_MODEM_Q6_FW, SMEM_RPM, SMEM_TZ, SMEM_SPSS, SMEM_HYP, NUM_SMEM_SUBSYSTEMS,&#125;; linux启动时会为其初始化，创建工作队列probe_work 123456for (i = 0; i &lt; NUM_SMD_SUBSYSTEMS; ++i) &#123; remote_info[i].remote_pid = i; remote_info[i].free_space = UINT_MAX; INIT_WORK(&amp;remote_info[i].probe_work, smd_channel_probe_worker); INIT_LIST_HEAD(&amp;remote_info[i].ch_list);&#125; 一个远端设备有多个通道，默认支持64个通道 创建SDM设备modem启动后会向linux发消息，触发smd中断，linux侧执行smd_modem_irq_handler smd_modem_irq_handler —&gt; handle_smd_irq —&gt; do_smd_probe 12345678910static void do_smd_probe(unsigned remote_pid)&#123; unsigned free_space; free_space = smem_get_free_space(remote_pid); if (free_space != remote_info[remote_pid].free_space) &#123; remote_info[remote_pid].free_space = free_space; schedule_work(&amp;remote_info[remote_pid].probe_work); &#125;&#125; 远端设备（比如modem）通过共享内存区域传递数据到linux侧，如果有free_space有变化（细节暂不研究）则触发smd_channel_probe_worker smd_channel_probe_worker —&gt; smd_channel_probe_now —&gt; smd_alloc_channel 从共享内存获取设备信息，得到设备名字（比如IPCRTR) 遍历所有通道 ，对未申请的通道进行申请 申请通道时会注册平台设备 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657static int smd_alloc_channel(struct smd_alloc_elm *alloc_elm, int table_id, struct remote_proc_info *r_info)&#123; /* probe_worker guarentees ch-&gt;type will be a valid type */ if (ch-&gt;type == SMD_APPS_MODEM) //设备类型是SMD_APPS_MODEM ch-&gt;notify_other_cpu = notify_modem_smd; else if (ch-&gt;type == SMD_APPS_QDSP) ch-&gt;notify_other_cpu = notify_dsp_smd; else if (ch-&gt;type == SMD_APPS_DSPS) ch-&gt;notify_other_cpu = notify_dsps_smd; else if (ch-&gt;type == SMD_APPS_WCNSS) ch-&gt;notify_other_cpu = notify_wcnss_smd; else if (ch-&gt;type == SMD_APPS_Q6FW) ch-&gt;notify_other_cpu = notify_modemfw_smd; else if (ch-&gt;type == SMD_APPS_RPM) ch-&gt;notify_other_cpu = notify_rpm_smd; if (smd_is_packet(alloc_elm)) &#123; //是包类型 ch-&gt;read = smd_packet_read; ch-&gt;write = smd_packet_write; ch-&gt;read_avail = smd_packet_read_avail; ch-&gt;write_avail = smd_packet_write_avail; ch-&gt;update_state = update_packet_state; ch-&gt;read_from_cb = smd_packet_read_from_cb; ch-&gt;is_pkt_ch = 1; &#125; else &#123; ch-&gt;read = smd_stream_read; ch-&gt;write = smd_stream_write; ch-&gt;read_avail = smd_stream_read_avail; ch-&gt;write_avail = smd_stream_write_avail; ch-&gt;update_state = update_stream_state; ch-&gt;read_from_cb = smd_stream_read; &#125; if (is_word_access_ch(ch-&gt;type)) &#123; ch-&gt;read_from_fifo = smd_memcpy32_from_fifo; ch-&gt;write_to_fifo = smd_memcpy32_to_fifo; &#125; else &#123; ch-&gt;read_from_fifo = smd_memcpy_from_fifo; ch-&gt;write_to_fifo = smd_memcpy_to_fifo; &#125; smd_memcpy_from_fifo(ch-&gt;name, alloc_elm-&gt;name, SMD_MAX_CH_NAME_LEN); ch-&gt;name[SMD_MAX_CH_NAME_LEN-1] = 0; ch-&gt;pdev.name = ch-&gt;name; ch-&gt;pdev.id = ch-&gt;type; SMD_INFO(\"smd_alloc_channel() '%s' cid=%d\\n\", ch-&gt;name, ch-&gt;n); mutex_lock(&amp;smd_creation_mutex); list_add(&amp;ch-&gt;ch_list, &amp;smd_ch_closed_list); mutex_unlock(&amp;smd_creation_mutex); platform_device_register(&amp;ch-&gt;pdev); 启动时会为modem创建多个通道，比如 IPCRTR：用于QMI数据收发 DATA40_CNTL：qti进程使用这个通道，对应的设备名字smdcntl8（在设备树中定义） smdcntl设备设备树中包含了smdpkt设备，linux启动时执行msm_smd_pkt_probe —&gt; smd_pkt_devicetree_init smd_pkt_devicetree_init查询设备树中smdpkt的配置，创建字符设备，操作函数为smd_pkt_fops 打开设备123456789101112int smd_pkt_open(struct inode *inode, struct file *file)&#123; //为SMD平台设备(比如DATA40_CNTL)添加平台驱动 r = smd_pkt_add_driver(smd_pkt_devp); if (smd_pkt_devp-&gt;ch == 0) &#123; //打开SMD通道 r = smd_named_open_on_edge(smd_pkt_devp-&gt;ch_name, smd_pkt_devp-&gt;edge, &amp;smd_pkt_devp-&gt;ch, smd_pkt_devp, ch_notify);//远端有数据发给linux时，调用ch_notify&#125; 写数据数据直接写入对应的smd通道里 1234567891011ssize_t smd_pkt_write(struct file *file, const char __user *_buf, size_t count, loff_t *ppos)&#123; r = smd_write_start(smd_pkt_devp-&gt;ch, count); ... r = smd_write_segment(smd_pkt_devp-&gt;ch, (void *)(buf + bytes_written), (count - bytes_written)); 读取数据123456789101112131415161718ssize_t smd_pkt_read(struct file *file, char __user *_buf, size_t count, loff_t *ppos)&#123; //等待数据 r = wait_event_interruptible(smd_pkt_devp-&gt;ch_read_wait_queue, !smd_pkt_devp-&gt;ch || (smd_cur_packet_size(smd_pkt_devp-&gt;ch) &gt; 0 &amp;&amp; smd_read_avail(smd_pkt_devp-&gt;ch)) || smd_pkt_devp-&gt;has_reset); //读取数据 pkt_size = smd_cur_packet_size(smd_pkt_devp-&gt;ch); r = smd_read(smd_pkt_devp-&gt;ch, (buf + bytes_read), (pkt_size - bytes_read)); 打开时通道时注册了回调ch_notify 12345static void ch_notify(void *priv, unsigned event)&#123; switch (event) &#123; case SMD_EVENT_DATA: &#123; check_and_wakeup_reader(smd_pkt_devp);//唤醒读取等待进程","categories":[],"tags":[],"keywords":[]},{"title":"linux USB host驱动","slug":"Linux系统/linux USB host 驱动","date":"2019-07-12T16:00:00.000Z","updated":"2019-07-13T07:33:45.263Z","comments":true,"path":"Linux系统/linux USB host 驱动/","link":"","permalink":"http://wzhchen/github.io/Linux系统/linux USB host 驱动/","excerpt":"介绍USB系统框架，只关注框架部分，不涉及细节","text":"介绍USB系统框架，只关注框架部分，不涉及细节 USB设备注册过程usb_add_hcd -&gt; register_root_hub -&gt; usb_new_device -&gt; device_add(添加设备) -&gt; usb_device_match(驱动匹配) -&gt; generic_probe -&gt; usb_set_configuration -&gt; device_add(添加接口) -&gt; usb_device_match(ID 匹配) -&gt; usb接口驱动的probe USB初始化usb_intusb_int初始化整个usb系统的基础部分 注册USB总线bus_register(&amp;usb_bus_type); 注册usbfs驱动usb_register(&amp;usbfs_driver); 注册usb hub驱动usb_hub_init -&gt; usb_register(&amp;hub_driver) 注册通用设备驱动 usb_register_device_driver(&amp;usb_generic_driver, THIS_MODULE) host总线初始化以msm ehci为例 初始化echi驱动数据结构ehci_init_driver(&amp;msm_hc_driver, &amp;msm_overrides); 使用ehci_hc_driver数据结构为基础 创建hcd 12hcd = usb_create_hcd(&amp;msm_hc_driver, &amp;pdev-&gt;dev, dev_name(&amp;pdev-&gt;dev)); ​ 其中msm_hc_driver在上一步初始化，以ehci_hc_driver为基础 ​ 重点：hcd-&gt;self是一条usb总线 123struct usb_hcd &#123; struct usb_bus self; /* hcd is-a bus */ ...... 添加hcd到系统中usb_add_hcd(hcd, hcd-&gt;irq, IRQF_SHARED) 向usb系统中注册一条总线usb_register_bus(&amp;hcd-&gt;self)) 创建一个USB设备，作为根hub rhdev = usb_alloc_dev(NULL, &amp;hcd-&gt;self, 0)hcd-&gt;self.root_hub = rhdev详见：usb设备创建 为该总线注册根hubregister_root_hub(hcd) 根hub注册过程 获取根hub的描述信息usb_get_device_descriptor(usb_dev, USB_DT_DEVICE_SIZE); 向usb系统中添加了一个usb设备：usb_new_device (usb_dev); 该设备是上一步创建的根hub设备struct usb_device \\usb_dev = hcd-&gt;self.root_hub;* usb设备创建usb_alloc_dev(struct usb_device parent, struct usb_bus bus, unsigned port1) 设备类型： 123456dev-&gt;dev.bus = &amp;usb_bus_type;dev-&gt;dev.type = &amp;usb_device_type;...if (unlikely(!parent)) &#123; root_hub = 1;&#125; 设备路径&amp;设备名字： ​ 根hub：很简单，路径为”0”, 名字直接是总线编号​ dev-&gt;devpath[0] = ‘0’;​ dev_set_name(&amp;dev-&gt;dev, “usb%d”, bus-&gt;busnum); ​ 普通设备​ hub设备自身（父设备为根hub）：路径为端口编号​ snprintf(dev-&gt;devpath, sizeof dev-&gt;devpath, “%d”, port1); ​ 普通设备（父设备为hub设备）：路径为hub路径+端口编号​ snprintf(dev-&gt;devpath, sizeof dev-&gt;devpath,”%s.%d”, parent-&gt;devpath, port1); ​ 设备名字：总线编号 + 设备路径​ dev_set_name(&amp;dev-&gt;dev, “%d-%s”, bus-&gt;busnum, dev-&gt;devpath); usb添加设备int usb_new_device(struct usb_device *udev) USB枚举设备usb_enumerate_device(udev) 获取USB配置：usb_get_configuration(udev) 显示usb设备信息announce_device(udev); 添加设备device_add(&amp;udev-&gt;dev)重点：会触发probe 创建endpoint设备usb_create_ep_devs(&amp;udev-&gt;dev, &amp;udev-&gt;ep0, udev) 123456ep_dev-&gt;udev = udev;ep_dev-&gt;dev.groups = ep_dev_groups;ep_dev-&gt;dev.type = &amp;usb_ep_device_type;ep_dev-&gt;dev.parent = parent;dev_set_name(&amp;ep_dev-&gt;dev, \"ep_%02x\", endpoint-&gt;desc.bEndpointAddress);device_register(&amp;ep_dev-&gt;dev); usb probe过程 查找驱动usb_device_match usb设备probe：generic_probe选择配置：usb_choose_configuration设置配置：usb_set_configuration （重点） usb接口probe：配置id表：usb驱动的id_tableusb_match_id(intf, usb_drv-&gt;id_table) 动态匹配（非常有用） usb 动态匹配表usb probe过程中，优先使用静态表（代码中写死，编译后不可更改），如果静态表中没有当前设备（usb 接口）则使用动态表 动态表由应用层写入 路径：/sys/bus/usb/driver/\\/new_id 格式：\\ \\ [InterfaceClass [refVendor refProduct]] usb 设置配置 usb_set_configuration 遍历当前配置的接口（通过usb_get_configuration从usb设备获取） 12345intf-&gt;dev.bus = &amp;usb_bus_type;intf-&gt;dev.type = &amp;usb_if_device_type;dev_set_name(&amp;intf-&gt;dev, \"%d-%s:%d.%d\", dev-&gt;bus-&gt;busnum, dev-&gt;devpath, configuration, alt-&gt;desc.bInterfaceNumber); 遍历当前配置的接口 添加接口：device_add(&amp;intf-&gt;dev) 重点：会触发probe hub初始化过程 添加usb接口时（device_add）触发probe，如果接口是hub，则执行hub_probe hub的匹配表：USB_CLASS_HUB=9 123456789101112static const struct usb_device_id hub_id_table[] = &#123; &#123; .match_flags = USB_DEVICE_ID_MATCH_VENDOR //指定产商的hub | USB_DEVICE_ID_MATCH_INT_CLASS, .idVendor = USB_VENDOR_GENESYS_LOGIC, .bInterfaceClass = USB_CLASS_HUB, .driver_info = HUB_QUIRK_CHECK_PORT_AUTOSUSPEND&#125;, &#123; .match_flags = USB_DEVICE_ID_MATCH_DEV_CLASS, //设备为hub .bDeviceClass = USB_CLASS_HUB&#125;, &#123; .match_flags = USB_DEVICE_ID_MATCH_INT_CLASS, //接口为hub .bInterfaceClass = USB_CLASS_HUB&#125;, &#123; &#125; /* Terminating entry */&#125;; hub_probe新建1个hub，配置hub（重点） 12345hub = kzalloc(sizeof(*hub), GFP_KERNEL)...INIT_WORK(&amp;hub-&gt;events, hub_event);usb_set_intfdata (intf, hub);hub_configure(hub, endpoint) hub_event是重点 配置hubhub_configure(struct usb_hub hub, struct usb_endpoint_descriptor endpoint) 获取hub的描述get_hub_descriptor(hdev, hub-&gt;descriptor) 获取hub设备的状态usb_get_status(hdev, USB_RECIP_DEVICE, 0, &amp;hubstatus) 获取hub的状态hub_hub_status(hub, &amp;hubstatus, &amp;hubchange) get_hub_status(hub-&gt;hdev, &amp;hub-&gt;status-&gt;hub) 创建端口设备 12345678for (i = 0; i &lt; maxchild; i++) &#123; ret = usb_hub_create_port_device(hub, i + 1); if (ret &lt; 0) &#123; dev_err(hub-&gt;intfdev, \"couldn't create port%d device.\\n\", i + 1); break; &#125;&#125; 123456port_dev-&gt;dev.groups = port_dev_group;port_dev-&gt;dev.type = &amp;usb_port_device_type;port_dev-&gt;dev.driver = &amp;usb_port_driver;dev_set_name(&amp;port_dev-&gt;dev, \"%s-port%d\", dev_name(&amp;hub-&gt;hdev-&gt;dev), port1);retval = device_register(&amp;port_dev-&gt;dev); 创建的端口在/sys/bus/usb/device/下可见 hub事件处理hub_event 处理hub下每个端口的事件 1234for (i = 1; i &lt;= hdev-&gt;maxchild; i++) &#123; ... port_event(hub, i);&#125; port_event 获取端口状态：hub_port_status(hub, port1, &amp;portstatus, &amp;portchange) 端口连接事件发生变化时，执行hub_port_connect_change hub端口连接事件hub_port_connect_change-&gt;hub_port_connect 端口下有设备，则先移除 12345if (udev) &#123; if (hcd-&gt;usb_phy &amp;&amp; !hdev-&gt;parent) usb_phy_notify_disconnect(hcd-&gt;usb_phy, udev-&gt;speed); usb_disconnect(&amp;port_dev-&gt;child);&#125; 创建一个usb设备udev = usb_alloc_dev(hdev, hdev-&gt;bus, port1) 初始化hub porthub_port_init(hub, udev, port1, i); 获取设备描述：usb_get_device_descriptor(udev, USB_DT_DEVICE_SIZE) 添加usb设备status = usb_new_device(udev);","categories":[{"name":"linux内核","slug":"linux内核","permalink":"http://wzhchen/github.io/categories/linux内核/"}],"tags":[{"name":"linux驱动","slug":"linux驱动","permalink":"http://wzhchen/github.io/tags/linux驱动/"},{"name":"USB","slug":"USB","permalink":"http://wzhchen/github.io/tags/USB/"}],"keywords":[{"name":"linux内核","slug":"linux内核","permalink":"http://wzhchen/github.io/categories/linux内核/"}]},{"title":"linux gadget 驱动","slug":"Linux系统/linux USB gadget 驱动","date":"2019-07-12T16:00:00.000Z","updated":"2019-07-17T03:01:48.915Z","comments":true,"path":"Linux系统/linux USB gadget 驱动/","link":"","permalink":"http://wzhchen/github.io/Linux系统/linux USB gadget 驱动/","excerpt":"介绍USB系统框架，只关注框架部分，不涉及细节 这里的USB设备控制器（UDC）驱动指作为其他usb主机控制器外设的usb硬件设备上底层硬件控制器的驱动，该硬件和驱动负责将一个usb设备依附于一个usb主机控制器上。 在usb设备控制器于gadget驱动中，我们主要关心几个核心的数据结构。描述一个usb设备控制器的usb_gadget，描述一个gadget驱动的usb_gadget_driver，表示一个传输请求的usb_request，描述一个端点的usb_ep，描述端点操作的usb_ep_ops结构体 研究时使用9x07平台","text":"介绍USB系统框架，只关注框架部分，不涉及细节 这里的USB设备控制器（UDC）驱动指作为其他usb主机控制器外设的usb硬件设备上底层硬件控制器的驱动，该硬件和驱动负责将一个usb设备依附于一个usb主机控制器上。 在usb设备控制器于gadget驱动中，我们主要关心几个核心的数据结构。描述一个usb设备控制器的usb_gadget，描述一个gadget驱动的usb_gadget_driver，表示一个传输请求的usb_request，描述一个端点的usb_ep，描述端点操作的usb_ep_ops结构体 研究时使用9x07平台 初始化流程## 添加udc设备 以ci3xxx_msm举例 初始化gadget ci13xxx_msm_probe-&gt;udc_probe 123456789101112udc = kzalloc(sizeof(struct ci13xxx), GFP_KERNEL);if (udc == NULL) return -ENOMEM;udc-&gt;lock = &amp;udc_lock;udc-&gt;regs = regs;udc-&gt;udc_driver = driver;udc-&gt;gadget.ops = &amp;usb_gadget_ops;udc-&gt;gadget.speed = USB_SPEED_UNKNOWN;udc-&gt;gadget.max_speed = USB_SPEED_HIGH;udc-&gt;gadget.is_otg = 0;udc-&gt;gadget.name = driver-&gt;name; udc-&gt;gadget.usb_core_id没有初始化，默认值为0 创建&amp;添加udc设备 retval = usb_add_gadget_udc(dev, &amp;udc-&gt;gadget); usb_add_gadget_udc_release(parent, gadget, NULL) 1234567891011121314udc = kzalloc(sizeof(*udc), GFP_KERNEL)dev_set_name(&amp;gadget-&gt;dev, \"gadget\");INIT_WORK(&amp;gadget-&gt;work, usb_gadget_state_work);device_initialize(&amp;udc-&gt;dev);udc-&gt;dev.release = usb_udc_release;udc-&gt;dev.class = udc_class;udc-&gt;dev.groups = usb_udc_attr_groups;udc-&gt;dev.parent = parent;ret = dev_set_name(&amp;udc-&gt;dev, \"%s\", kobject_name(&amp;parent-&gt;kobj));udc-&gt;gadget = gadget;list_add_tail(&amp;udc-&gt;list, &amp;udc_list);ret = device_add(&amp;udc-&gt;dev); 添加android设备 从android_probe开始 ​ 从设备树中获取usb_core_id，默认值为0，创建出来的设备是android0 ​ android_dev = kzalloc(sizeof(*android_dev), GFP_KERNEL); ​ android_create_device(struct android_dev *dev, u8 usb_core_id) 123snprintf(device_node_name, ANDROID_DEVICE_NODE_NAME_LENGTH, \"android%d\", usb_core_id);dev-&gt;dev = device_create(android_class, NULL, MKDEV(0, usb_core_id), ​ 创建一个android设备，其中usb_core_id默认为0 初始化设备(android0)默认支持的功能(function) 1234android_dev-&gt;name = pdev-&gt;name;android_dev-&gt;disable_depth = 1;android_dev-&gt;functions = supported_list ? supported_list : default_functions; 其中supported_list从设备树获取，默认为空，既使用default_functions 绑定udc设备usb_composite_probe(&amp;android_usb_driver) 123456789101112131415161718int usb_composite_probe(struct usb_composite_driver *driver)&#123; struct usb_gadget_driver *gadget_driver; u8 core_id; //初始化android_usb_driver下的gadget_driver core_id = driver-&gt;gadget_driver.usb_core_id; driver-&gt;gadget_driver = composite_driver_template; gadget_driver = &amp;driver-&gt;gadget_driver; gadget_driver-&gt;function = (char *) driver-&gt;name; gadget_driver-&gt;driver.name = driver-&gt;name; gadget_driver-&gt;max_speed = driver-&gt;max_speed; if (core_id) gadget_driver-&gt;usb_core_id = core_id; return usb_gadget_probe_driver(gadget_driver);&#125; usb_gadget_probe_driver(struct usb_gadget_driver *driver) 根据usb_core_id找到udc（在ci13xxx_msm_probe中添加的） 将udc和driver绑定：udc_bind_to_driver udc_bind_to_driverret = driver-&gt;bind(udc-&gt;gadget, driver); 执行composite_bind composite_bind创建 usb_composite_dev设备 12cdev = kzalloc(sizeof *cdev, GFP_KERNEL)cdev-&gt;gadget = gadget; 执行usb_composite_driver的bind，此处是android_bind android_bind初始化产品信息（可以通过应用层修改，修改/sys/class/android_usb/android0目录下的文件）初始化&amp;创建function（可以通过应用层修改，修改/sys/class/android_usb/android0/functions） 应用层修改&amp;使能参数&amp;配置修改：修改修改/sys/class/android_usb/android0下的文件，暂不关注系统 使能 应用层修改/sys/class/android_usb/android0/enable文件触发android_enable 添加配置usb_add_config(cdev, &amp;conf-&gt;usb_config, android_bind_config);android_bind_config —&gt; android_bind_enabled_functions 遍历配置里的所有function，执行相应的bind_config 连接，触发host端的连接请求usb_gadget_connect(cdev-&gt;gadget); gadget-&gt;ops-&gt;pullup(gadget, 1) gadget配置host端请求代码：USB_REQ_GET_DESCRIPTOR –&gt; USB_DT_DEVICE 123456789101112131415161718192021222324252627282930313233343536373839404142int usb_get_device_descriptor(struct usb_device *dev, unsigned int size)&#123; struct usb_device_descriptor *desc; int ret; if (size &gt; sizeof(*desc)) return -EINVAL; desc = kmalloc(sizeof(*desc), GFP_NOIO); if (!desc) return -ENOMEM; ret = usb_get_descriptor(dev, USB_DT_DEVICE, 0, desc, size);//获取第0个配置 if (ret &gt;= 0) memcpy(&amp;dev-&gt;descriptor, desc, size); kfree(desc); return ret;&#125;int usb_get_descriptor(struct usb_device *dev, unsigned char type, unsigned char index, void *buf, int size)&#123; int i; int result; memset(buf, 0, size); /* Make sure we parse really received data */ for (i = 0; i &lt; 3; ++i) &#123; /* retry on length 0 or error; some devices are flakey */ result = usb_control_msg(dev, usb_rcvctrlpipe(dev, 0), USB_REQ_GET_DESCRIPTOR, USB_DIR_IN, (type &lt;&lt; 8) + index, 0, buf, size, USB_CTRL_GET_TIMEOUT); if (result &lt;= 0 &amp;&amp; result != -ETIMEDOUT) continue; if (result &gt; 1 &amp;&amp; ((u8 *)buf)[1] != type) &#123; result = -ENODATA; continue; &#125; break; &#125; return result;&#125; device端请求：入口：composite_setup 123456switch (ctrl-&gt;bRequest) &#123; /* we handle all standard USB descriptors */ case USB_REQ_GET_DESCRIPTOR: switch (w_value &gt;&gt; 8) &#123; case USB_DT_CONFIG: value = config_desc(cdev, w_value); 1234567891011121314151617181920static int config_desc(struct usb_composite_dev *cdev, unsigned w_value)&#123; ...//根据w_value(配置索引号，一般为0)获取配置 return config_buf(c, speed, cdev-&gt;req-&gt;buf, type);&#125;static int config_buf(struct usb_configuration *config, enum usb_device_speed speed, void *buf, u8 type)&#123; c = buf; c-&gt;bLength = USB_DT_CONFIG_SIZE; c-&gt;bDescriptorType = type; /* wTotalLength is written later */ c-&gt;bNumInterfaces = config-&gt;next_interface_id; c-&gt;bConfigurationValue = config-&gt;bConfigurationValue; c-&gt;iConfiguration = config-&gt;iConfiguration; c-&gt;bmAttributes = USB_CONFIG_ATT_ONE | config-&gt;bmAttributes; c-&gt;bMaxPower = encode_bMaxPower(speed, config);&#125; 接口数量c-&gt;bNumInterfaces = config-&gt;next_interface_id next_interface_id在usb_interface_id中修改，每调用一次usb_interface_id，next_interface_id加1 usb_interface_id在各个function的bind_config函数中调用 f_rndis的interface数量为2，包含控制接口和数据接口 12345678910/* allocate instance-specific interface IDs */status = usb_interface_id(c, f);if (status &lt; 0) goto fail;rndis-&gt;ctrl_id = status;...status = usb_interface_id(c, f);if (status &lt; 0) goto fail;rndis-&gt;data_id = status; f_rmnet的interface数量可变，具体如下： 使能android接口之前需要设置rmnet_transports（f_rmnet/transports文件） rmnet_function_bind_config 遍历rmnet_transports配置，执行frmnet_init_port frmnet_init_port初始化rmnet_port，记录port总数量 bind：每个端口执行一次frmnet_bind_config , frmnet_bind —&gt; usb_interface_id，为每个端口添加一个interface ​ rmnet用为拨号接口有更复杂的其它功能，不在此描述 f_diag的interface数量可变，具体如下： 使能android接口之前需要设置diag_clients（f_diag/clients文件） diag_function_bind_config遍历diag_clients配置，执行diag_function_add bind：diag_function_bind —&gt; usb_interface_id，为每个配置添加一个interface f_serail的interface数量可变，具体如下： 使能android接口之前需要设置serial_transports（f_serial/transports文件） serial_function_bind_config遍历serial_transports配置，执行gserial_init_port gserial_init_port初始化gserial_ports，记录port总数量 bind: 每个端口执行一次gser_alloc，gser_bind —&gt; usb_interface_id，为每个端口添加一个interface 1234567891011121314151617181920212223for (i = 0; i &lt; ports; i++) &#123; config-&gt;f_serial_inst[i] = usb_get_function_instance(\"gser\"); if (IS_ERR(config-&gt;f_serial_inst[i])) &#123; err = PTR_ERR(config-&gt;f_serial_inst[i]); goto err_gser_usb_get_function_instance; &#125; config-&gt;f_serial[i] = usb_get_function(config-&gt;f_serial_inst[i]); if (IS_ERR(config-&gt;f_serial[i])) &#123; err = PTR_ERR(config-&gt;f_serial[i]); goto err_gser_usb_get_function; &#125; &#125; serial_initialized = 1;bind_config: for (i = 0; i &lt; ports; i++) &#123; err = usb_add_function(c, config-&gt;f_serial[i]); if (err) &#123; pr_err(\"Could not bind gser%u config\\n\", i); goto err_gser_usb_add_function; &#125; &#125; 接口编号host端的驱动根据device端的接口编号来匹配 接口编号按照注册顺序生成（遍历functions），比如： 1234echo diag &gt; f_diag/clientsecho tty,smd,smd &gt; f_serial/transportsecho QTI,BAM_DMUX &gt; f_rmnet/transportsecho diag,serial,rmnet &gt; functions 编号0：diag 编号1： tty 编号2：smd 编号3：smd 编号4：rmnet endpoint从usb 主机到设备称为 out 端点，从设备到主机称为in 端点。 创建endpointudc初始化时会创建endpoint 1234567891011121314151617181920212223242526272829303132for (i = 0; i &lt; hw_ep_max/2; i++) &#123; for (j = RX; j &lt;= TX; j++) &#123; int k = i + j * hw_ep_max/2; struct ci13xxx_ep *mEp = &amp;udc-&gt;ci13xxx_ep[k]; scnprintf(mEp-&gt;name, sizeof(mEp-&gt;name), \"ep%i%s\", i, (j == TX) ? \"in\" : \"out\"); mEp-&gt;lock = udc-&gt;lock; mEp-&gt;device = &amp;udc-&gt;gadget.dev; mEp-&gt;td_pool = udc-&gt;td_pool; mEp-&gt;ep.name = mEp-&gt;name; mEp-&gt;ep.ops = &amp;usb_ep_ops; usb_ep_set_maxpacket_limit(&amp;mEp-&gt;ep, k ? USHRT_MAX : CTRL_PAYLOAD_MAX); INIT_LIST_HEAD(&amp;mEp-&gt;qh.queue); mEp-&gt;qh.ptr = dma_pool_alloc(udc-&gt;qh_pool, GFP_KERNEL, &amp;mEp-&gt;qh.dma); if (mEp-&gt;qh.ptr == NULL) retval = -ENOMEM; else memset(mEp-&gt;qh.ptr, 0, sizeof(*mEp-&gt;qh.ptr)); /* skip ep0 out and in endpoints */ if (i == 0) continue; list_add_tail(&amp;mEp-&gt;ep.ep_list, &amp;udc-&gt;gadget.ep_list); &#125; &#125; 创建的endpoint由adget.ep_list管理 1234567891011static const struct usb_ep_ops usb_ep_ops = &#123; .enable = ep_enable, .disable = ep_disable, .alloc_request = ep_alloc_request, .free_request = ep_free_request, .queue = ep_queue, .dequeue = ep_dequeue, .set_halt = ep_set_halt, .set_wedge = ep_set_wedge, .fifo_flush = ep_fifo_flush,&#125;; 重点关注usb_ep_ops 申请endpoint每个接口(interface)bind时会申请endpoint，比如： 12345ep = usb_ep_autoconfig(cdev-&gt;gadget, &amp;gser_fs_in_desc);if (!ep) goto fail;gser-&gt;port.in = ep;ep-&gt;driver_data = cdev; /* claim */ 数据通讯host端的控制请求响应 udc_irq —&gt; isr_tr_complete_handler —&gt; udc-&gt;driver-&gt;setup composite_setup(struct usb_gadget gadget, const struct usb_ctrlrequest ctrl) ​ composite_setup实现通用的控制命令，function可以扩展实现更多的控制命令 host端数据传输 -&gt; device端 ​ udc_irq —&gt; isr_tr_complete_low —&gt; mReq-&gt;req.complete usb的数据通讯基于endpoint，每个endpoint都一个地址，双向通过这个地址通讯 传输数据之前，需要申请usb_request 123456789101112131415struct usb_request *alloc_ep_req(struct usb_ep *ep, int len, int default_len)&#123; struct usb_request *req; req = usb_ep_alloc_request(ep, GFP_ATOMIC); if (req) &#123; req-&gt;length = len ?: default_len; req-&gt;buf = kmalloc(req-&gt;length, GFP_ATOMIC); if (!req-&gt;buf) &#123; usb_ep_free_request(ep, req); req = NULL; &#125; &#125; return req;&#125; 发送数据（in端点） 填充req的数据，举例：smd_read(pi-&gt;ch, req-&gt;buf, avail); 调用usb_ep_queue发送 12345static inline int usb_ep_queue(struct usb_ep *ep, struct usb_request *req, gfp_t gfp_flags)&#123; return ep-&gt;ops-&gt;queue(ep, req, gfp_flags);&#125; 发送完成：执行req-&gt;complete 接收数据（out端点） 执行req-&gt;complete 参考usb gadget usb host数据传输 USB中的端点详细了解","categories":[{"name":"linux内核","slug":"linux内核","permalink":"http://wzhchen/github.io/categories/linux内核/"}],"tags":[{"name":"linux驱动","slug":"linux驱动","permalink":"http://wzhchen/github.io/tags/linux驱动/"},{"name":"USB","slug":"USB","permalink":"http://wzhchen/github.io/tags/USB/"}],"keywords":[{"name":"linux内核","slug":"linux内核","permalink":"http://wzhchen/github.io/categories/linux内核/"}]},{"title":"cmdline初始流程","slug":"Linux系统/cmdline初始流程","date":"2019-07-07T16:00:00.000Z","updated":"2019-07-08T09:04:10.587Z","comments":true,"path":"Linux系统/cmdline初始流程/","link":"","permalink":"http://wzhchen/github.io/Linux系统/cmdline初始流程/","excerpt":"记录cmdline初始流程","text":"记录cmdline初始流程 方式一setup_arch-&gt;setup_machine_fdt ​ early_init_dt_scan_nodes-&gt;early_init_dt_scan_chosen加载设备树里的cmdline 方式二如果没有设备树，或者设备树查找machine失败，则使用 setup_arch-&gt;setup_machine_tags 直接使用默认值CONFIG_CMDLINE（由menuconfig配置 mdesc-&gt;fixup函数修改","categories":[{"name":"linux内核","slug":"linux内核","permalink":"http://wzhchen/github.io/categories/linux内核/"}],"tags":[{"name":"cmdline","slug":"cmdline","permalink":"http://wzhchen/github.io/tags/cmdline/"}],"keywords":[{"name":"linux内核","slug":"linux内核","permalink":"http://wzhchen/github.io/categories/linux内核/"}]},{"title":"linux根文件系统挂载过程","slug":"Linux系统/linux根文件系统挂载过程","date":"2019-07-02T16:00:00.000Z","updated":"2019-07-08T08:39:56.036Z","comments":true,"path":"Linux系统/linux根文件系统挂载过程/","link":"","permalink":"http://wzhchen/github.io/Linux系统/linux根文件系统挂载过程/","excerpt":"记录rootfs的初始化流程","text":"记录rootfs的初始化流程 配置cmdline中添加root的配置，比如root=ubi0:rootfs root_dev_setup函数中使用root的配置，暂存到saved_root_name中 __setup(“root=”, root_dev_setup); cmdline中添加rootfs的可读写属性 只读：ro 可读写：rw __setup(“ro”, readonly);__setup(“rw”, readwrite); 流程第一阶段start_kernelvfs_caches_initmnt_initinit_rootfs：注册rootfs 第二阶段populate_rootfsdefault_rootfs：创建/dev/console和/root节点 rootfs_initcall(populate_rootfs); 调用流程 start_kernel-&gt;kernel_initkernel_init_freeabledo_basic_setupdo_initcalls-&gt;rootfs_initcall 注：此时rootfs还没有挂载，现在的根目录是ramfs 第三阶段start_kernel-&gt;kernel_init prepare_namespace mount_block_root（mtd或ubi类型则在些阶段挂载） mount_root：挂载注：此时挂载的路径是ramfs的/root 第四阶段把ramfs的/root切换到/ sys_mount(“.”, “/“, NULL, MS_MOVE, NULL);sys_chroot(“.”);","categories":[{"name":"linux内核","slug":"linux内核","permalink":"http://wzhchen/github.io/categories/linux内核/"}],"tags":[{"name":"rootfs","slug":"rootfs","permalink":"http://wzhchen/github.io/tags/rootfs/"}],"keywords":[{"name":"linux内核","slug":"linux内核","permalink":"http://wzhchen/github.io/categories/linux内核/"}]},{"title":"mdm9x07内存使用分析","slug":"芯片方案/mdm9x07/mdm9x07内存使用分析","date":"2019-06-30T16:00:00.000Z","updated":"2019-07-02T08:08:42.365Z","comments":true,"path":"芯片方案/mdm9x07/mdm9x07内存使用分析/","link":"","permalink":"http://wzhchen/github.io/芯片方案/mdm9x07/mdm9x07内存使用分析/","excerpt":"主篇文章主要记录mdm9x07的内存使用情况","text":"主篇文章主要记录mdm9x07的内存使用情况 内存总大小aboot将内存大小更新到设备树中，kernel启动时从设备树获取 setup_machine_fdt-&gt;early_init_dt_scan_nodes-&gt;early_init_dt_scan_memory 内存划分系统将内存划分成4大块 modem DSP使用，默认大小71M 在设备树modem_adsp_mem中配置，使用”removed-dma-pool”从主内存中划分一块保留给mode DSP使用 实际使用大小由modem固件决定，目前为70M external_image_mem，默认大小4M 作用未知（猜测是CPU的RPM核使用了这块区域），在设备树external_image_mem中配置 audio_mem，默认大小4M 在设备树audio_region中配置，使用shared-dma-pool从主内存中划分一块保留给audio使用，系统将其划分成CMA内存 默认CMA内存，默认大小4M 在defconfig（CONFIG_CMA_SIZE_MBYTES）或cmdline（cma）中配置，供系统申请DMA内存使用 | 功能 | 内存占用 | 备注 || ——————- | ———– | ——————- || 系统原子操作 | 256K | || qcom,pm | 4K | 实际只使用了256字节 || nand | 8K+4K+4K+4K | 实际只使用了520字节 || msm_hsusb | 4K+4K | || sdhci | 16K+16K | 2个sdhci控制器 || soc:qcom,lpm-levels | 8K | || pil_boot | 1M+4K | || emac | 20K | | 其中pil_boot由subsystem_get触发，modem_powerup没有modem分区的设备，由psmd进程加载有modem分区的设备由kernel加载 保留内存 Memory: 31404K/126976K available (7349K kernel code, 990K rwdata, 3280K rodata, 312K init, 1016K bss, 95572K reserved) linux系统本身可见所以内存，但系统运行需要保留一些内存供其它功能使用，具体如下（以上述日志举例）： kernel运行需要保留一部分，日志中“7349K kernel code, 990K rwdata, 3280K rodata, 312K init, 1016K bss”的部分，总共12947K 页表使用16K，细节可查看arm_mm_memblock_reserve 设备树88K（4K对齐） 上一节中描述的保留内存，71M(modem_adsp_mem)+4M(audio_mem)+4M(CMA) ioremap保留1625K 总共95572K 注：其中external_image_mem为no-map内存，不记录到保留内存范畴 available内存 Memory: 31404K/126976K available (7349K kernel code, 990K rwdata, 3280K rodata, 312K init, 1016K bss, 95572K reserved) 以上述日志举例，硬件内存大小为128M 设备树中external_image_mem保留的内存为no-map，不映射到linux系统下，linux系统下的available内存会减去这一部分（4M），剩下124M（126976K） 31404K=126976K -95572K 应用层可见总内存 root@router:~# free total used free shared buffers cachedMem: 41476 39020 2456 128 0 6712 包含available内存的31404K kernel启动后会释放启动时占用的一部分内存，具体如下 释放kernel中_init段空间312K 设备树中modem_adsp_mem指定了no-map-fixup，映射完成后可释放ioremap占用的空间544K 设备树中modem_adsp_mem配置为71M，modem只使用了70M，释放多余的空间1M 另外CMA内存（8M:包含audio_mem和默认CMA）作为应用层可见内存 以上部分加起来总共41476K","categories":[{"name":"芯片方案","slug":"芯片方案","permalink":"http://wzhchen/github.io/categories/芯片方案/"}],"tags":[{"name":"mdm9x07","slug":"mdm9x07","permalink":"http://wzhchen/github.io/tags/mdm9x07/"}],"keywords":[{"name":"芯片方案","slug":"芯片方案","permalink":"http://wzhchen/github.io/categories/芯片方案/"}]},{"title":"","slug":"allegro/allegro","date":"2019-05-13T08:08:23.981Z","updated":"2019-05-15T11:08:46.321Z","comments":true,"path":"allegro/allegro/","link":"","permalink":"http://wzhchen/github.io/allegro/allegro/","excerpt":"","text":"设置类关闭器件重叠DRC检查 setup -&gt; constrains -&gt; modes -&gt; design modes(package)，在“package to package”后面选择“off”。 制作封装https://wenku.baidu.com/view/a906eb1289eb172dec63b704.html 铺铜设置及删除死铜的方法https://blog.csdn.net/sy_lixiang/article/details/9142153 Allegro输出gerber文件https://wenku.baidu.com/view/4f97eb5a1ed9ad51f01df2db.html","categories":[],"tags":[],"keywords":[]},{"title":"TensorFlow笔记","slug":"深度学习/TensorFlow笔记","date":"2019-04-01T03:48:37.886Z","updated":"2019-01-30T01:38:20.907Z","comments":true,"path":"深度学习/TensorFlow笔记/","link":"","permalink":"http://wzhchen/github.io/深度学习/TensorFlow笔记/","excerpt":"","text":"安装TensorFlow首先TensorFlow官网有详细的说明 linux环境比较简单，以下记录是关于Windows的 虽然官网有详细的说明，但实际还是会遇到问题的，如果想做一些改进问题就会更多了，以下是我的安装记录 安装Python 注意一定要安装64位版本，比如我一不小心就装了个32位版本，只好卸载重新安装 python -v …. Python 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 23 2018, 23:31:17) [MSC v.1916 32 bit (Intel)] on win32 点击这里下载Python3.6.8 64位版本 安装Visual Studio Code 强烈推荐安装，可以在IDE里编写、调试代码 该IDE里提供的Terminal也比Windows自带的cmd好用，后续地命令可以在这个工具里执行 安装虚拟环境（官方也说了推荐这种方式） 首先进入想要创建虚拟环境的目录 执行以下命令，在该目录下创建名为venv的虚拟环境，后续所有包都会安装在这个目录下 12pip install virtualenvvirtualenv --system-site-packages -p python ./venv 官方提供的命令会报错，命令中不能使用python3 连续执行以下几个命令，具体可参考官方说明 1234567.\\venv\\Scripts\\activate #激活虚拟环境pip install --upgrade pip #更新&amp;安装pippip install --upgrade tensorflow #更新&amp;安装tensorflow#测试会用到的一些包pip install matplotlibpip install opencv-pythonpip install tqdm 如果import cv2报错，则可以换成其它版本 12pip uninstall opencv-pythonpip install opencv-python==3.4.5.20 设置VScode使用python虚拟环境 在VScode的扩展面板里搜索并安装”Python for VScode“ 打开设置（在界面左下角），搜索python.pythonPath 修改Workspace Settings，指定刚才的虚拟环境python的路径，比如 E:\\DL\\venv\\Scripts\\python.exe 修改完成后，需要重启VScode 基础知识shape理解shape表示张量各维度的数据长度，比如shape=(1,2,3)，3个数字表示3维 第1个维度数字是1，表示只第1个维度的数据长度是1 第2个维度数字是2，表示只第2个维度的数据长度是2 第3个维度数字是3，表示只第3个维度的数据长度是3 12[x, y] #只有一个维度，长度是2，所以这个张量的shape=(2,), 或者(2,0)[[[x,y,z], [x,y,z]]] #这个张量的shape=(1,2,3) CNN原理https://www.jianshu.com/p/fe428f0b32c1 注：多通道卷积：将每个通道的卷积结果相加，得到1个feature map，而不是多个feature map 如像素大小12x12, 3通道（rgb）对应的shape为12x12x3，与8个3x3的卷积核卷积后得到的shape为：10x10x8 tf函数定义变量相关的函数tf.placeholder定义占位符 12x = tf.placeholder(\"float\",[None,784])y_ = tf.placeholder(\"float\", [None,10]) 定义一个输入x，有784个维度，但具体的数据暂未给出 tf.Variable1W = tf.Variable(&lt;initial-value&gt;, name=&lt;optional-name&gt;) 用于生成一个初始值为initial-value的变量。必须指定初始化值 举例： 12W = tf.Variable(tf.zeros([784,10]))b = tf.Variable(tf.zeros([10])) 定义2个矩阵变量，分别是权重和偏置，训练过程就是不段变换这2个矩阵\\ tf.get_variable12W = tf.get_variable(name, shape=None, dtype=tf.float32, initializer=None, regularizer=None, trainable=True, collections=None) 获取已存在的变量（要求不仅名字，而且初始化方法等各个参数都一样），如果不存在，就新建一个。可以用各种初始化方法，不用明确指定值。 tf.variable_scope设置变量名 12with tf.variable_scope('mynet'): b = tf.Variable(tf.zeros([10]), name='b') 定义的变量名是：mynet/b tf.zeros_like1tf.zeros_like(tensor, dtype=None, name=None, optimize=True) 创建一个所有元素都设置为零的张量，张量的类型与tensor相同 tf.truncated_normal产生随机正太分布 变量操作相关的函数tf.matmu矩阵乘法 softmax：回归函数，将给定的输入x，权重W和偏置b计算所得值回归到[0-1]的范围 1y = tf.nn.softmax(tf.matmul(x,W) + b) tf.reduce_sum累加和 以下代码为求交叉熵 1cross_entropy = -tf.reduce_sum(y_*tf.log(y)) tf.cast1cast(x, dtype, name=None) 将x的数据格式转化成dtype.例如，原来x的数据格式是bool，那么将其转化成float以后，就能够将其转化成0和1的序列。反之也可以 tf.reduce_mean求平均值 tf.squeeze1squeeze(input,axis=None,name=None,squeeze_dims=None) 该函数返回一个张量，这个张量是将原始input中所有维度为1的那些维都删掉的结果axis可以用来指定要删掉的为1的维度，此处要注意指定的维度必须确保其是1，否则会报错 例子： 12345# 't' 是一个维度是[1, 2, 1, 3, 1, 1]的张量tf.shape(tf.squeeze(t)) # [2, 3]， 默认删除所有为1的维度# 't' 是一个维度[1, 2, 1, 3, 1, 1]的张量tf.shape(tf.squeeze(t, [2, 4])) # [1, 2, 3, 1]，标号从零开始，只删掉了2和4维的1 tf.slice这个函数的作用是从输入数据input中提取出一块切片 切片的尺寸是size，切片的开始位置是begin。 切片的尺寸size表示输出tensor的数据维度，其中size[i]表示在第i维度上面的元素个数。 参考https://www.jianshu.com/p/71e6ef6c121b tf.concat1tf.concat(values, axis, name='concat') 其中： values应该是一个tensor的list或者tuple。 axis则是我们想要连接的维度。 tf.concat返回的是连接后的tensor。 比如，如果list中的tensor的shape都是（2，2，2），如果此时的axis为2，即连接第三个维度，那么连接后的shape是（2，2，4），具体表现为对应维度的堆砌。例子如下： 123t1 = [[[1, 2], [2, 3]], [[4, 4], [5, 3]]]t2 = [[[7, 4], [8, 4]], [[2, 10], [15, 11]]]tf.concat([t1, t2], axis=-1) 输出结果为 1&lt;tf.Tensor 'concat_2:0' shape=(2, 2, 4) dtype=int32&gt; 再sess.run（）一下拿出具体tensor为： 12345[[[ 1, 2, 7, 4], [ 2, 3, 8, 4]], [[ 4, 4, 2, 10], [ 5, 3, 15, 11]]] 可见符合（2，2，4）的shape。 tf.train.string_input_producer 这个函数需要传入一个文件名list，系统会自动将它转为一个文件名队列。 此外tf.train.string_input_producer还有两个重要的参数，一个是num_epochs，它就是我们上文中提到的epoch数。另外一个就是shuffle，shuffle是指在一个epoch内文件的顺序是否被打乱。 summarytensorboard 作为一款可视化神器，可以说是学习tensorflow时模型训练以及参数可视化的法宝。 而在训练过程中，主要用到了tf.summary()的各类方法，能够保存训练过程以及参数分布图并在tensorboard显示。 参考TensorFlow框架(2)之TensorBoard详解 TFRecordTfrecord是tensorflow官方推荐的训练数据存储格式，它更容易与网络应用架构相匹配。 Tfrecord本质上是二进制的Protobuf数据，因而其读取、传输的速度更快。Tfrecord文件的每一条记录都是一个tf.train.Example的实例。 使用tfrecord文件格式的另一个好处是数据结构统一，屏蔽了底层的数据结构。在类似于图像分类的任务中，原始数据是各个图片以单独的小文件的形式存在，label又以文件夹的形式存在，处理这样的数据比较麻烦，比如随机打乱，分batch等操作；而所有原始数据转换为一个或几个单独的tfrecord文件后处理起来就会比较方便。 生成tfrecord文件何把原始数据转换为tfrecord文件格式，请参考下面的代码片段： 1234567891011121314151617181920212223def _bytes_feature(value): if not isinstance(value, list): value = [value] return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))def _int64_feature(value): if not isinstance(value, list): value = [value] return tf.train.Feature(int64_list=tf.train.Int64List(value=value))# 建立tfrecorder writerwriter = tf.python_io.TFRecordWriter('csv_train.tfrecords')for i in xrange(train_values.shape[0]): image_raw = train_values[i].tostring() features=tf.train.Features(feature=&#123; 'image_raw': _bytes_feature([image_raw]), 'label': _int64_feature([train_labels[i]]) &#125;) # build example protobuf example = tf.train.Example(features=features) writer.write(example.SerializeToString())writer.close() 使用tfrecord文件 定义与保存文件时对应的解析文件方法 12345678910def parse_exmp(serial_exmp): features=&#123;'image_raw': tf.FixedLenFeature([3], tf.int64), 'label': tf.FixedLenFeature([3],tf.float32) &#125; feats = tf.parse_single_example(serial_exmp, features=features) image = tf.decode_raw(features['image_raw'], tf.uint8) #根据实际情况对image格式做转换 #.... label = tf.cast(features['label'], tf.int32) return image, label 使用TFRecordDataset读取tfrecord文件 12345678910def get_tf_data(): '''读取tfrecord数据''' dataset = tf.data.TFRecordDataset([tf_filename1, tf_filename2]) dataset = dataset.map(parse_exmp) dataset = dataset.shuffle(1000) dataset = dataset.repeat(1).batch(batch_size) iterator = dataset.make_one_shot_iterator() one_element = iterator.get_next() return one_element 使用session获取实际的数据 12345678sess = tf.Session()while(True): try: result = sess.run(one_element) print(result[0], result[1]) except tf.errors.OutOfRangeError: print(\"end!\") break tf.data的使用参考:https://zhuanlan.zhihu.com/p/38421397 模型的保存与恢复(Saver)将训练好的模型参数保存起来，以便以后进行验证或测试，这是我们经常要做的事情。tf里面提供模型保存的是tf.train.Saver()模块。 模型保存，先要创建一个Saver对象：如 1saver=tf.train.Saver() 在创建这个Saver对象的时候，有一个参数我们经常会用到，就是 max_to_keep 参数，这个是用来设置保存模型的个数，默认为5，即 max_to_keep=5，保存最近的5个模型。如果你想每训练一代（epoch)就想保存一次模型，则可以将 max_to_keep设置为None或者0，如： 1saver=tf.train.Saver(max_to_keep=0) 但是这样做除了多占用硬盘，并没有实际多大的用处，因此不推荐。 当然，如果你只想保存最后一代的模型，则只需要将max_to_keep设置为1即可，即 1saver=tf.train.Saver(max_to_keep=1) 创建完saver对象后，就可以保存训练好的模型了，如： 1saver.save(sess,'model/mnist.ckpt',global_step=step) 生成的文件在model目录下，文件名的前缀是123456789101112第一个参数sess,这个就不用说了。第二个参数设定保存的路径和名字，第三个参数将训练的次数作为后缀加入到模型名字中。&gt; saver.save(sess, &apos;my-model&apos;, global_step=0) ==&gt; filename: &apos;my-model-0&apos;&gt; ...&gt; saver.save(sess, &apos;my-model&apos;, global_step=1000) ==&gt; filename: &apos;my-model-1000&apos;模型的恢复用的是restore()函数，它需要两个参数restore(sess, save_path)，save_path指的是保存的模型路径。我们可以使用tf.train.latest_checkpoint（）来自动获取最后一次保存的模型。如：```pythonmodel_file=tf.train.latest_checkpoint(&apos;model/&apos;)saver.restore(sess,model_file) PB文件生成pb文件 tf.graph_util.convert_variables_to_constants函数，会将计算图中的变量取值以常量的形式保存。 1234567891011121314151617import tensorflow as tffrom tensorflow.python.platform import gfile if __name__ == \"__main__\": a = tf.Variable(tf.constant(5.,shape=[1]),name=\"a\") b = tf.Variable(tf.constant(6.,shape=[1]),name=\"b\") c = a + b init = tf.global_variables_initializer() sess = tf.Session() sess.run(init) #导出当前计算图的GraphDef部分 graph_def = tf.get_default_graph().as_graph_def() #保存指定的节点，并将节点值保存为常数 output_graph_def = tf.graph_util.convert_variables_to_constants(sess,graph_def,['add']) #将计算图写入到模型文件中 model_f = tf.gfile.GFile(\"model.pb\",\"wb\") model_f.write(output_graph_def.SerializeToString()) 分析pb文件 使用Tensorboard分析pb文件，有两种方法 方法一： 利用pb文件恢复计算图 利用Tensorboard查看计算图的结构 方法二 利用tensorflow提供的tools里的import_pb_to_tensorboard.py这个工具，但是这个工具linux版本的tensorflow没有安装（Win下默认安装），需要的可以去下载[https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/tools] 方法一 从pb文件中恢复计算图 12345678import tensorflow as tfmodel = 'model.pb' #请将这里的pb文件路径改为自己的graph = tf.get_default_graph()graph_def = graph.as_graph_def()graph_def.ParseFromString(tf.gfile.GFile(model, 'rb').read())tf.import_graph_def(graph_def, name='graph')summaryWriter = tf.summary.FileWriter('log/', graph) 利用Tensorboard查看计算图 在命令行运行以下命令，启动Tensorboard 12#命令行运行里执行tensorboard --logdir log/ #这里的路径就是1中最后一行图保存的路径，请根据自己的需要更改 方法二利用tools里面的import_pb_to_tensorboard.py工具 123#命令行python -m tensorflow.python.tools.import_pb_to_tensorboard --model_dir=\"your_path/model.pb\" --log_dir=\"your_log_path\" tensorboard --logdir=\"your_log_path\" #启动tensorboard 或者 12345678910import sysimport osfrom tensorflow.python.tools.import_pb_to_tensorboard import import_to_tensorboardif __name__ == \"__main__\": model = sys.argv[1] log_dir = sys.argv[2] import_to_tensorboard(model, log_dir) #调用命令 os.system('tensorboard --logdir='+log_dir) #启动tensorboard 经过查看源码，第二种方法其实是对第一种方法的包装。两种方法是一致的，只不过第二种方法更加便捷。 示例代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798#coding=UTF-8import sysimport tensorflow as tfimport input_datamnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)#占位符，x:输入，y_:实际结果x = tf.placeholder(\"float\",[None,784])y_ = tf.placeholder(\"float\", [None,10])def weight_variable(shape): initial = tf.truncated_normal(shape, stddev=0.1) return tf.Variable(initial)def bias_variable(shape): initial = tf.constant(0.1, shape=shape) return tf.Variable(initial)def conv2d(x, W): return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')def max_pool_2x2(x): return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')#用于调试#batch = mnist.train.next_batch(50)#x_image = tf.reshape(batch[0], [-1,28,28,1])#y_ = batch[1]#第一层卷积的权重和偏置，卷积核大小5x5#原始数据只有1个通道#卷积数量32个，从32个不同的维度来提取特征，将产生32个输出通道W_conv1 = weight_variable([5, 5, 1, 32])b_conv1 = bias_variable([32])#将输入（原始数据）转化成4维向量x_image = tf.reshape(x, [-1,28,28,1])#第一层卷积 -&gt; relu -&gt; 池化h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)h_pool1 = max_pool_2x2(h_conv1)#第二层卷积的权重和偏置，卷积核大小5x5#上一层有32个输出通道，因此这一层有32个输入通道#卷积数量64个，从64个不同的维度来提取特征，将产生64个输出通道W_conv2 = weight_variable([5, 5, 32, 64])b_conv2 = bias_variable([64])#第二层卷积 -&gt; relu -&gt; 池化h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)h_pool2 = max_pool_2x2(h_conv2)#全连接层的权重和偏置#上一层有64个输出通道，输出的尺寸是7x7#设置全连接数量为1024，从1024个维度提取特征，将产生1024个1维度的输出通道W_fc1 = weight_variable([7 * 7 * 64, 1024])b_fc1 = bias_variable([1024])#将输入（第二层输出）转化成2维向量h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])#计算连接层的结果h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)#Dropout层，防止或减轻过拟合，一般用在全连接层。keep_prob = tf.placeholder(\"float\")h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)#输出层的权重和偏置#上一层（全连接层）有1024个输出通道#设置10个输出，分别代码数字0-9的概率W_fc2 = weight_variable([1024, 10])b_fc2 = bias_variable([10])#计算输出层的结果，矩阵乘+归1化处理y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)#成本（交叉熵）随机梯度递减cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))sess = tf.InteractiveSession()sess.run(tf.initialize_all_variables())#开始训练for i in range(20000): batch = mnist.train.next_batch(50) if i%100 == 0: train_accuracy = accuracy.eval(feed_dict=&#123; x:batch[0], y_: batch[1], keep_prob: 1.0&#125;) print \"step %d, training accuracy %g\"%(i, train_accuracy) train_step.run(feed_dict=&#123;x: batch[0], y_: batch[1], keep_prob: 0.5&#125;)#测试结果print \"test accuracy %g\"%accuracy.eval(feed_dict=&#123; x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0&#125;) 参考链接学习过程中参考了以下文章 TensorFlow框架(1)之Computational Graph详解TensorFlow框架(2)之TensorBoard详解TensorFlow框架(3)之MNIST机器学习入门TensorFlow框架(4)之CNN卷积神经网络详解","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://wzhchen/github.io/categories/深度学习/"}],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://wzhchen/github.io/tags/TensorFlow/"},{"name":"环境搭建","slug":"环境搭建","permalink":"http://wzhchen/github.io/tags/环境搭建/"}],"keywords":[{"name":"深度学习","slug":"深度学习","permalink":"http://wzhchen/github.io/categories/深度学习/"}]},{"title":"MTCNN tensorflow实现","slug":"深度学习/MTCNN tensorflow实现","date":"2019-04-01T03:48:37.825Z","updated":"2019-07-21T11:08:28.128Z","comments":true,"path":"深度学习/MTCNN tensorflow实现/","link":"","permalink":"http://wzhchen/github.io/深度学习/MTCNN tensorflow实现/","excerpt":"","text":"依赖环境需要安装opencv、numpy、tqdm 123pip install opencv-pythonpip install numpypip install tqdm #显示处理进度 参考代码https://github.com/LeslieZhoa/tensorflow-MTCNN 使用流程 手动下载数据，并解压到data目录 下载用于人脸检测的训练数据：WIDER_train 下载用于人脸对齐的训练数据：lfw_5590&amp;net_7876 WIDER_train的数量标注，阈值比较宽，尽可能多的将人脸标注，甚至遮挡很多的也被标注了 数据预处理 生成tfrecords数据 执行训练 PNet训练步骤 使用“python gen_12net_data.py”命令，对WIDER_train下的图片进行处理，生成3种图片，大小均调整为12x12： 正样本，截取图片中的人脸区域，生成坐标文件，产生约40万张 负样本，截取图片中的非人脸区域，生成坐标文件，产生约100万张图片 部分样本，截图图片中包含部分人脸区域，生成坐标文件，产生约100万张图片 使用“python gen_landmark_aug.py 12”命令，对lfw_5590&amp;net_7876下的图片进行处理，生成landmark图片，大小也调整为12x12，截图图片中的人脸区域，生成人脸对齐点的坐标文件，产生约17万张图片 使用”python gen_imglist_pnet.py“命令，从上述4种数据中按比例提取数据（步骤1中的3处数据比例为1:3:1，步骤2种的数据取全部），生成新的坐标文件 使用”python gen_tfrecords.py 12“命令，按照步骤3中生成的文件，提取图片，生成tfrecord数据 使用”python train.py 12 “命令，使用tfrecord数据进行训练 RNet训练步骤 使用“python gen_hard_example.py 12”命令， 制作PNnet tfrecord文件新方法默认的方法会产生大量的中间文件，导致大量IO操作，生成文件的速度非常慢，因此设计一种新的方法： 从人脸框标签（或者叫坐标）文件(wider_face_train.txt)中获取数据 使用随机方法，生成正样本、负样本、部分人脸样本3种数据样本，以变量的形式保存在内存中 从人脸对齐标签文件（trainImageList.txt）中获取数据，截取人脸，将数据追加到步骤2的变量中 使用前面步骤产生的类变量，从image中提取数据 将变量中的坐标在归一化处理 将变量随机打乱 将变量的数据转成tfrecord格式，存入文件 人脸数据集https://github.com/polarisZhao/awesome-face","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://wzhchen/github.io/categories/深度学习/"}],"tags":[{"name":"MTCNN","slug":"MTCNN","permalink":"http://wzhchen/github.io/tags/MTCNN/"},{"name":"tensorflow","slug":"tensorflow","permalink":"http://wzhchen/github.io/tags/tensorflow/"}],"keywords":[{"name":"深度学习","slug":"深度学习","permalink":"http://wzhchen/github.io/categories/深度学习/"}]},{"title":"Caffe笔记","slug":"深度学习/Caffe笔记","date":"2019-04-01T03:48:37.721Z","updated":"2019-01-14T07:53:02.217Z","comments":true,"path":"深度学习/Caffe笔记/","link":"","permalink":"http://wzhchen/github.io/深度学习/Caffe笔记/","excerpt":"","text":"安装caffe2caffe2的官网有详细的说明 官方提供多种安装方式，我这边选择ubuntu16.04版本，使用源码自己编译，具体步骤使用参考官方文档，安装依赖包、下载代码，编译 系统默认使用是python2，在安装过程中报错 12切换到python3pip install --user pyyaml AI Camera Demo测试 下载官方代码 编译，编译时会报错误 Could not download junit.jar (junit:junit:4.12) 实际用不到，修改app/build.gradle文件，去掉对junit的引用","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://wzhchen/github.io/categories/深度学习/"}],"tags":[{"name":"caffe2","slug":"caffe2","permalink":"http://wzhchen/github.io/tags/caffe2/"}],"keywords":[{"name":"深度学习","slug":"深度学习","permalink":"http://wzhchen/github.io/categories/深度学习/"}]},{"title":"linux串口驱动","slug":"Linux系统/linux串口驱动","date":"2018-03-21T16:00:00.000Z","updated":"2019-01-14T07:55:31.539Z","comments":true,"path":"Linux系统/linux串口驱动/","link":"","permalink":"http://wzhchen/github.io/Linux系统/linux串口驱动/","excerpt":"工作中需要调试linux系统下的串口驱动，因特殊需求需要创建一些虚拟串口，工作中需要将串口驱动的整个流程全部梳理，中途中遇到了不少问题，现在问题已经基本解决，现将整个过程做个总结记录。","text":"工作中需要调试linux系统下的串口驱动，因特殊需求需要创建一些虚拟串口，工作中需要将串口驱动的整个流程全部梳理，中途中遇到了不少问题，现在问题已经基本解决，现将整个过程做个总结记录。 整体框图首先给出整体框图，后面结合代码详细介绍各个流程 UART驱动注册uart_driver数据结构向kernel中注册一个串口驱动之前，需要先准备一个uart_driver结构该，uart_driver就是串口的驱动 1234567/* 虚拟uart驱动 结构体*/static struct uart_driver virtual_uart_driver = &#123; .owner = THIS_MODULE, .driver_name = \"virtual_serial\", .dev_name = \"COM\", .nr = VIRTUAL_UART_PORT_NR,&#125;; driver_name：串口驱动的名字，可以自定义dev_name：使用该驱动注册串口设备的设备名前缀，也可以自定义nr：该驱动允许注册的设备数量，尽可能按照实际需求来写，注册串口驱动时会根据nr来申请资源 uart_register_driver注册驱动准备好uart_driver数据结构后，调用uart_register_driver即可将其注册进kernel. 接下来看看uart_register_driver里做了哪些事情（请注意nr的使用） 1234567891011121314151617181920212223242526272829303132333435363738394041//为uart_driver-&gt;state, 每个端口需要一个statedrv-&gt;state = kzalloc(sizeof(struct uart_state) * drv-&gt;nr, GFP_KERNEL);if (!drv-&gt;state) goto out;//创建一个tty_driver数据结构，并为各个端口分配资源normal = alloc_tty_driver(drv-&gt;nr);if (!normal) goto out_kfree;//uart_driver中的tty_driver指向新创建的tty_driver，方便其他代码根据uart_driver查找tty_driver drv-&gt;tty_driver = normal;//一系统的参数初始化normal-&gt;driver_name = drv-&gt;driver_name;normal-&gt;name = drv-&gt;dev_name;normal-&gt;major = drv-&gt;major;normal-&gt;minor_start = drv-&gt;minor;normal-&gt;type = TTY_DRIVER_TYPE_SERIAL;normal-&gt;subtype = SERIAL_TYPE_NORMAL;normal-&gt;init_termios = tty_std_termios;normal-&gt;init_termios.c_cflag = B9600 | CS8 | CREAD | HUPCL | CLOCAL;normal-&gt;init_termios.c_ispeed = normal-&gt;init_termios.c_ospeed = 9600;normal-&gt;flags = TTY_DRIVER_REAL_RAW | TTY_DRIVER_DYNAMIC_DEV;normal-&gt;driver_state = drv;//设置tty_driver的ops，uart_ops由kernel核心代码提供tty_set_operations(normal, &amp;uart_ops);/* * Initialise the UART state(s). */for (i = 0; i &lt; drv-&gt;nr; i++) &#123; struct uart_state *state = drv-&gt;state + i; struct tty_port *port = &amp;state-&gt;port; //初始化每个tty端口，核心部分是tty_buffer_init tty_port_init(port); port-&gt;ops = &amp;uart_port_ops; port-&gt;close_delay = HZ / 2; /* .5 seconds */ port-&gt;closing_wait = 30 * HZ;/* 30 seconds */&#125;//注册tty_driverretval = tty_register_driver(normal);if (retval &gt;= 0) return retval; uart_port数据结构向kernel中添加串口之前，需要准备好uart_port数据结构 uart_port与底层的硬件密切相关，对于驱动框架而言，最重要的是uart_ops，定义了操作硬件的接口 12345678910111213141516static struct uart_ops virtual_uart_pops = &#123; .tx_empty = virtual_tx_empty, .set_mctrl = virtual_set_mctrl, .get_mctrl = virtual_get_mctrl, .stop_tx = virtual_nothing, .start_tx = virtual_start_tx, .stop_rx = virtual_nothing, .break_ctl = virtual_break_ctl, .startup = virtual_startup, .shutdown = virtual_nothing, .set_termios = virtual_set_termios, .type = virtual_type, .release_port = virtual_nothing, .request_port = virtual_nothing1, .config_port = virtual_config_port,&#125;; 另外1个重要成员是line，指示该uart_port属于驱动中的第几个端口，对于到应用层的串口编号 uart_add_one_port 添加串口uart_driver注册好后，需要将uart_port添加进去 uart_driver只是一框架，不具备与硬件打交道的能力，与硬件打交道是uart_port，因此一般调试驱动时更多的是在修改uart_port，但查找问题的过程一般要贯穿整个流程 12345678910for(i = 0; i &lt; VIRTUAL_UART_PORT_NR; i++) &#123; virtual_uart_port[i].ops = &amp;virtual_uart_pops; virtual_uart_port[i].attr_group = &amp;virtual_attr_group; virtual_uart_port[i].type = PORT_VIRTUAL; virtual_uart_port[i].line = i; //将准备好的uart_port添加到uart_driver中 ret = uart_add_one_port(&amp;virtual_uart_driver, virtual_uart_port+i); if (unlikely(ret)) goto remove_port;&#125; 现在来看看uart_add_one_port干了些什么事（以下只将重要部分展现出来） 123456789101112131415161718int uart_add_one_port(struct uart_driver *drv, struct uart_port *uport)&#123; struct uart_state *state; struct tty_port *port; struct device *tty_dev; state = drv-&gt;state + uport-&gt;line; port = &amp;state-&gt;port; state-&gt;uart_port = uport; uport-&gt;state = state; //使用serial_core提供的代码对端口进行配置，会调用uart_port的ops里的接口对硬件做配置 uart_configure_port(drv, state, uport); /* * Register the port whether it's detected or not. This allows * setserial to be used to alter this port's parameters. */ tty_dev = tty_port_register_device_attr(port, drv-&gt;tty_driver, uport-&gt;line, uport-&gt;dev, port, uport-&gt;tty_groups);&#125; 再来跟踪一下tty_port_register_device_attr 1234567891011struct device *tty_port_register_device_attr(struct tty_port *port, struct tty_driver *driver, unsigned index, struct device *device, void *drvdata, const struct attribute_group **attr_grp)&#123; //tty_port_link_devie非常简单，将tty_driver的uart_port指向当前的port // driver-&gt;ports[index] = port; tty_port_link_device(port, driver, index); return tty_register_device_attr(driver, index, device, drvdata, attr_grp);&#125; 继续跟踪tty_register_device_attr（以下只将重要部分展现出来） 12345678910111213141516171819202122232425struct device *tty_register_device_attr(struct tty_driver *driver, unsigned index, struct device *device, void *drvdata, const struct attribute_group **attr_grp)&#123; char name[64]; dev_t devt = MKDEV(driver-&gt;major, driver-&gt;minor_start) + index; struct device *dev = NULL; if (driver-&gt;type == TTY_DRIVER_TYPE_PTY) pty_line_name(driver, index, name); else tty_line_name(driver, index, name); if (!(driver-&gt;flags &amp; TTY_DRIVER_DYNAMIC_ALLOC)) &#123; //初始化字符设备tty_driver-&gt;cdev,并添加进kernel，文件操作使用tty_fops retval = tty_cdev_add(driver, devt, index, 1); &#125; dev = kzalloc(sizeof(*dev), GFP_KERNEL); dev-&gt;devt = devt; dev_set_name(dev, \"%s\", name); retval = device_register(dev);&#125; 各数据结构的关系经过一系列的注册及初始化过程后，可以得到以下关系图 open uart，打开串口应用层打开串口通常是通过打开/dev/下的节点来实现，应用层打开串口后就可以像操作普通文件一样来操作串口了，下面详细讲述一下open串口的具体流程 ## tty_open 首先根据VFS可以查找到tty_fops，因此打开/dev/COMx时会调用tty_open，tty_open会做许多初始化 申请一个tty_struct，每个串口只有1个tty_struct，如果多个应用打开同一个串口时，不会申请新的，直接使用已经申请好的； 将tty_struct与当前的文件描述符进行绑定（关闭串口时会用到，如果还有其它文件描述符占用tty_struct，关闭串口时则不会释放tty_struct，否则会释放）； 调用tty_struct-&gt;ops-&gt;open打开tty，做进一步的打开操作（向下一层进攻，开始研究tty_struct的申请过程） 其实对串口本身不相关的初始化 申请tty_struct12345678910111213141516171819202122232425262728static int tty_open(struct inode *inode, struct file *filp)&#123; struct tty_struct *tty; struct tty_driver *driver = NULL; int index; dev_t device = inode-&gt;i_rdev; //根据device（有设备号）可以查找刚才注册的tty_driver，同时也可以得到index（第几个串口） driver = tty_lookup_driver(device, filp, &amp;noctty, &amp;index); //在tty_driver中取出第index个tty_struct指针，没有别的应用打开该串口时，则返回的是一个空指针 /* check whether we're reopening an existing tty */ tty = tty_driver_lookup_tty(driver, inode, index); if (IS_ERR(tty)) &#123; retval = PTR_ERR(tty); goto err_unlock; &#125; &#125; if (tty) &#123; //如果有别的应用打开了这个串口，则只需要将计数加1 tty_lock(tty); retval = tty_reopen(tty); if (retval &lt; 0) &#123; tty_unlock(tty); tty = ERR_PTR(retval); &#125; &#125; else /* Returns with the tty_lock held for now */ tty = tty_init_dev(driver, index); //如果没有别的应用打开这个串口，需要自己创建tty_struct 进一步来看tty_init_dev（以下只将重要部分展现出来） 1234567891011121314151617181920struct tty_struct *tty_init_dev(struct tty_driver *driver, int idx)&#123; struct tty_struct *tty; int retval; //重点是通过alloc_tty_strcut来申请1个tty_struct tty = alloc_tty_struct(driver, idx); //将tty_driver中的tty_struct指向新申请的tty_struct，便于其他应用直接使用 //初始化tty_struct的termios retval = tty_driver_install_tty(driver, tty); //初始化tty_sturct-&gt;tty_port if (!tty-&gt;port) tty-&gt;port = driver-&gt;ports[idx]; tty-&gt;port-&gt;itty = tty; //这也是一个重要的东西 retval = tty_ldisc_setup(tty, tty-&gt;link); return tty;&#125; 来看看alloc_tty_struct，就是一系统的初始化（以下只将重要部分展现出来） 123456789101112131415struct tty_struct *alloc_tty_struct(struct tty_driver *driver, int idx)&#123; struct tty_struct *tty; tty = kzalloc(sizeof(*tty), GFP_KERNEL); tty-&gt;magic = TTY_MAGIC; //这是一个重要的地方，使用N_TYY作为tty的ldisc，简化成tty-&gt;ldisc-&gt;ops = tty_ldisc_N_TTY tty_ldisc_init(tty); tty-&gt;driver = driver; //tty_struct的ops直接使用tty_driver的ops，对于串口就是uart_ops tty-&gt;ops = driver-&gt;ops; tty-&gt;index = idx; tty_line_name(driver, idx, tty-&gt;name); return tty;&#125; n_tty注意：tty的数据读取主要由tty_ldisc_N_TTY来完成 n_tty负责tty的读写控制，各种数据缓存、阻塞、调度处理等另外也要处理tty的字符转换，比如回显、换行转回车等 在申请tty_struct时调用了tty_ldisc_setup，现在来看看tty_ldisc_setup（以下只将重要部分展现出来） 12345678910int tty_ldisc_setup(struct tty_struct *tty, struct tty_struct *o_tty)&#123; struct tty_ldisc *ld = tty-&gt;ldisc; int retval; //使用tty_ldisc_N_TTY-&gt;open打开，即执行n_tty_open retval = tty_ldisc_open(tty, ld); if (retval) return retval; return 0;&#125; n_tty_open会初始化处理数据需要的各类数据结构，本次工作没有对n_tty做深入研究，因此不作进一步展开 uart_open打开串口的最后一重要部分就是执行uart_open，uart_open由serial_core.c提供，完成串口的初始操作 来看下uart_open干了哪些事（同样只将重要部分展现出来） 12345678910111213141516171819static int uart_open(struct tty_struct *tty, struct file *filp)&#123; struct uart_driver *drv = (struct uart_driver *)tty-&gt;driver-&gt;driver_state; int retval, line = tty-&gt;index; struct uart_state *state = drv-&gt;state + line; struct tty_port *port = &amp;state-&gt;port; //打开计算，关闭时会用到 port-&gt;count++; tty-&gt;driver_data = state; state-&gt;uart_port-&gt;state = state; tty_port_tty_set(port, tty);//port-&gt;tty = tty //做进一步处理 retval = uart_startup(tty, state, 0); return retval;&#125; uart_open没干什么事情，都丢给了uart_startup来处理 12345678910111213static int uart_startup(struct tty_struct *tty, struct uart_state *state, int init_hw)&#123; struct tty_port *port = &amp;state-&gt;port; //如果已经初始过，则直接退出 if (port-&gt;flags &amp; ASYNC_INITIALIZED) return 0; uart_port_startup(tty, state, init_hw); //标记已经成功初始化 set_bit(ASYNCB_INITIALIZED, &amp;port-&gt;flags); return retval;&#125; 不过uart_startup也没干什么事，又丢给了uart_port_startup处理 123456789101112131415161718192021222324252627282930313233static int uart_port_startup(struct tty_struct *tty, struct uart_state *state, int init_hw)&#123; struct uart_port *uport = state-&gt;uart_port; unsigned long page; int retval = 0; if (uport-&gt;type == PORT_UNKNOWN) return 1; //为发送申请4Kbytes的FIFO if (!state-&gt;xmit.buf) &#123; /* This is protected by the per port mutex */ page = get_zeroed_page(GFP_KERNEL); if (!page) return -ENOMEM; state-&gt;xmit.buf = (unsigned char *) page; uart_circ_clear(&amp;state-&gt;xmit); &#125; //调用最底层的硬件startup来初始化硬件 retval = uport-&gt;ops-&gt;startup(uport); if (retval == 0) &#123; if (uart_console(uport) &amp;&amp; uport-&gt;cons-&gt;cflag) &#123; tty-&gt;termios.c_cflag = uport-&gt;cons-&gt;cflag; uport-&gt;cons-&gt;cflag = 0; &#125; //打开串口时会配置默认波特率，需要特别注意 uart_change_speed(tty, state, NULL); &#125; return retval;&#125; 分析到这里，就已经从应用层打开串口到底层硬件初始的所有流程，此时底层硬件的startup需要根据实际硬件来编写，此次工作中是一种特殊的虚拟串口驱动，因此startup会相对比较简单。 1234567891011121314static int virtual_startup(struct uart_port *port)&#123; struct uart_port *phy_port; //获取虚拟串口绑定的硬件串口，将硬件串口的波特率等信息复制到虚拟串口 phy_port = get_phy_uart_by_config(port-&gt;line); if(phy_port) &#123; struct tty_struct *vir_tty = port-&gt;state-&gt;port.tty; struct tty_struct *phy_tty = phy_port-&gt;state-&gt;port.tty; vir_tty-&gt;termios.c_cflag = phy_tty-&gt;termios.c_cflag; &#125; return 0;&#125; 各数据结构的关系经过一系统初始后，可以得到以下关系图 write uart，串口写流程向串口中写数据分成几个层次,每一层都分工明确 tty_write​ do_tty_write​ n_tty_write​ uart_write/uart_put_char​ 底层硬件驱动_start_tx​ handle_tx tty_write功能相对比较简,tty_write调用do_tty_write 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758static inline ssize_t do_tty_write( ssize_t (*write)(struct tty_struct *, struct file *, const unsigned char *, size_t), struct tty_struct *tty, struct file *file, const char __user *buf, size_t count)&#123; ssize_t ret, written = 0; unsigned int chunk; chunk = 2048; if (test_bit(TTY_NO_WRITE_SPLIT, &amp;tty-&gt;flags)) chunk = 65536; if (count &lt; chunk) chunk = count; //为tty_struct-&gt;write_buf准备一段空间,有一点小小算法在效率和内存占用上取一个平衡 /* write_buf/write_cnt is protected by the atomic_write_lock mutex */ if (tty-&gt;write_cnt &lt; chunk) &#123; unsigned char *buf_chunk; if (chunk &lt; 1024) chunk = 1024; buf_chunk = kmalloc(chunk, GFP_KERNEL); if (!buf_chunk) &#123; ret = -ENOMEM; goto out; &#125; kfree(tty-&gt;write_buf); tty-&gt;write_cnt = chunk; tty-&gt;write_buf = buf_chunk; &#125; //循环将数据从用户态复制到write_buf中,然后调用n_tty_write发送 /* Do the write .. */ for (;;) &#123; size_t size = count; if (size &gt; chunk) size = chunk; ret = -EFAULT; if (copy_from_user(tty-&gt;write_buf, buf, size)) break; ret = write(tty, file, tty-&gt;write_buf, size); if (ret &lt;= 0) break; written += ret; buf += ret; count -= ret; if (!count) break; //每写完一次调度一次,因为n_tty_write只是将数据写入缓存 //底层硬件发送一般比较慢,调度一次可以更加充分的利用CPU ret = -ERESTARTSYS; if (signal_pending(current)) break; cond_resched(); &#125; return ret;&#125; do_tty_write,将数据分次发给n_tty_write,n_tty_write会做更加复杂的处理,因为linux将tty数据收发的主要工作交给了n_tty ##n_tty_write_ n_tty_write的代码比较多,这里就不贴出来了,描述一下它的几种重要流程 处理tty的回显 通过tty_write_room(用调用uart_write_room)获取底层xmit.buf可用空间 调用uart_write将数据写入串口的xmit.buf中 如果底层xmit.buf的空间不足导致数据没有发送完,则将当前进程挂起,等待唤醒,由tty-&gt;write_wait控制 uart_writeuart_write负责将数据写入xmit.buf,然后调用uart_start启动底层发送 1234567891011121314151617181920212223242526272829303132static int uart_write(struct tty_struct *tty, const unsigned char *buf, int count)&#123; struct uart_state *state = tty-&gt;driver_data; struct uart_port *port; struct circ_buf *circ; unsigned long flags; int c, ret = 0; port = state-&gt;uart_port; circ = &amp;state-&gt;xmit; spin_lock_irqsave(&amp;port-&gt;lock, flags); while (1) &#123; c = CIRC_SPACE_TO_END(circ-&gt;head, circ-&gt;tail, UART_XMIT_SIZE); if (count &lt; c) c = count; //如果circ中没有可用空间了则退出,底层中断会不停的中取走数据 if (c &lt;= 0) break; memcpy(circ-&gt;buf + circ-&gt;head, buf, c); circ-&gt;head = (circ-&gt;head + c) &amp; (UART_XMIT_SIZE - 1); buf += c; count -= c; ret += c; &#125; spin_unlock_irqrestore(&amp;port-&gt;lock, flags); //通知底层,可以执行发送动作 uart_start(tty); return ret;&#125; uart_startuart_start简单的调用底层驱动的start_tx 底层驱动的start_tx一般只是打开发送中断（芯片tx fifo中没有数据则产生中断,数据发完后再关闭中断） handle_tx底层驱动的发送中断函数，负责从circ_buf中取数据，然写入寄存器将数据发送到硬件端口 1234567891011121314151617181920static void handle_tx(struct uart_port *port)&#123; struct circ_buf *xmit = &amp;port-&gt;state-&gt;xmit; int tx_count; unsigned int tf_pointer = 0; tx_count = uart_circ_chars_pending(xmit); while (tf_pointer &lt; tx_count) &#123; //循环从xmit.buf中取数据并发送出去 &#125; //数据发完后，circ_buf中没有写入新的数据，则xmit会为空，此时将硬件中断关闭 if (uart_circ_empty(xmit)) msm_hsl_stop_tx(port); if (uart_circ_chars_pending(xmit) &lt; WAKEUP_CHARS) &#123; //如果circ_buf中为的数据少于临界值了，则唤醒正在等待的进程，告诉它可以继续写数据了 uart_write_wakeup(port); &#125;&#125; 发送流程到此为止，整个发送流程已经梳理完毕，附上流程图 read uart，串口读流程包含2部分 open uart时，底层驱动会打开串口的接收功能，硬件接收到数据后会调用rx中断服务函数，数据的入口既是中断服务函数： handle_rx​ tty_insert_flip_xx​ flush_to_ldisc​ n_tty_receive_buf2 应用层读取串口数据 tty_read​ n_tty_read​ copy_from_read_buf handle_rx底层驱动的接收中断函数，负责从硬件FIFO中读取数据然后写入到驱动层的buf中。 1234567891011121314151617181920212223242526272829static void handle_rx(struct uart_port *port, unsigned int misr)&#123; struct tty_struct *tty = port-&gt;state-&gt;port.tty; int count = 0; //从硬件读取当前FIFO中有多少数据 if (misr &amp; UARTDM_ISR_RXSTALE_BMSK) &#123; count = msm_hsl_read(port, regmap[vid][UARTDM_RX_TOTAL_SNAP]) - msm_hsl_port-&gt;old_snap_state; msm_hsl_port-&gt;old_snap_state = 0; &#125; else &#123; count = 4 * (msm_hsl_read(port, regmap[vid][UARTDM_RFWR])); msm_hsl_port-&gt;old_snap_state += count; &#125; /* and now the main RX loop */ while (count &gt; 0) &#123; unsigned int c; //循环将FIFO中的数据读取出来，放到驱动层的buf中 /* TODO: handle sysrq */ /* if (!uart_handle_sysrq_char(port, c)) */ tty_insert_flip_string(tty-&gt;port, (char *) &amp;c, (count &gt; 4) ? 4 : count); count -= 4; &#125; //唤醒处理接收buf的工作队列 tty_flip_buffer_push(tty-&gt;port);&#125; ##flush_to_ldisc flush_to_ldisc会调用 n_tty_receive_buf2处于接收到的数据，代码比较复杂，只做简单的功能众介绍 检查n_tty_data的可用空间，如果应用层没有及时将数据读走，则不会从驱动层读取数据，同时做流控制操作 有可用空间的情况下，会将驱动层的数据读取到n_tty_data中 根据当前tty的模式，会将接收到的数据做转换处理，要完成终端协议，这里的处理会比较多 唤醒应用层的读取挂起进程 ##tty_read 功能相对比较简,tty_read调用n_tty_read（同样只将重要部分展现出来） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546static ssize_t n_tty_read(struct tty_struct *tty, struct file *file, unsigned char __user *buf, size_t nr)&#123; struct n_tty_data *ldata = tty-&gt;disc_data; unsigned char __user *b = buf; DECLARE_WAITQUEUE(wait, current); int c; int minimum, time; ssize_t retval = 0; long timeout; unsigned long flags; int packet; //根据termios.c_cc[VTIME]和termios.c_cc[VMIN]计算出单次读取操作的超时时间 minimum = time = 0; timeout = MAX_SCHEDULE_TIMEOUT; if (!ldata-&gt;icanon) &#123; minimum = MIN_CHAR(tty); if (minimum) &#123; time = (HZ / 10) * TIME_CHAR(tty); if (time) ldata-&gt;minimum_to_wake = 1; else if (!waitqueue_active(&amp;tty-&gt;read_wait) || (ldata-&gt;minimum_to_wake &gt; minimum)) ldata-&gt;minimum_to_wake = minimum; &#125; else &#123; timeout = (HZ / 10) * TIME_CHAR(tty); ldata-&gt;minimum_to_wake = minimum = 1; &#125; &#125; packet = tty-&gt;packet; //如果没有数据可读取，当前进程挂起，通过read_wait来唤醒 add_wait_queue(&amp;tty-&gt;read_wait, &amp;wait); while (nr) &#123; if (!input_available_p(tty, 0)) &#123; //如果没有数据，则挂起进程 timeout = schedule_timeout(timeout); continue; &#125; //copy_from_read_buf：从n_tty_data数据结构中读取数据 uncopied = copy_from_read_buf(tty, &amp;b, &amp;nr); &#125; return retval;&#125; 读取流程到此为止，整个接收流程已经梳理完毕，附上流程图","categories":[{"name":"linux内核","slug":"linux内核","permalink":"http://wzhchen/github.io/categories/linux内核/"}],"tags":[{"name":"linux驱动","slug":"linux驱动","permalink":"http://wzhchen/github.io/tags/linux驱动/"},{"name":"串口","slug":"串口","permalink":"http://wzhchen/github.io/tags/串口/"},{"name":"tty","slug":"tty","permalink":"http://wzhchen/github.io/tags/tty/"}],"keywords":[{"name":"linux内核","slug":"linux内核","permalink":"http://wzhchen/github.io/categories/linux内核/"}]},{"title":"i.MX 6ULL研究笔记_软件篇","slug":"芯片方案/imx6/imx6ull方案研究_软件篇","date":"2018-01-17T16:00:00.000Z","updated":"2019-01-14T07:50:55.664Z","comments":true,"path":"芯片方案/imx6/imx6ull方案研究_软件篇/","link":"","permalink":"http://wzhchen/github.io/芯片方案/imx6/imx6ull方案研究_软件篇/","excerpt":"主篇文章主要记录imx6的研究过程，将工作中有的到的重要部分提炼出来，主要描述与软件相关的内容。 相关文章：i.MX 6ULL研究笔记_硬件篇","text":"主篇文章主要记录imx6的研究过程，将工作中有的到的重要部分提炼出来，主要描述与软件相关的内容。 相关文章：i.MX 6ULL研究笔记_硬件篇 搭建编译工程i.mx6官方提供的软件开发指导是基于yocto工程，文档中包含了许多内容，比如： 指导如何配置主机（需要安装哪些包）； 指导如何下载yocto工程（不包含实际代码）； 如果配置编译，执行编译（编译过程中下载代码）； …… yocto开发模式的优点： 编译工程也集成非常多的软、硬件支持； 可编译出各种类型的系统（虚拟系统、带图形界面系统、PC系统等待）； yocto开发模式的缺点： 对开发者要求比较高； 编译执行速度非常慢； 编译出错不容易定位； 结合实际情况，我们不选yocto开发模式，自己搭建编译工程 源码获取自己搭建编译工程需要单独下载源码fresscale的代码存放在http://git.freescale.com/git 根据yocto指导手册可以找到i.MX6ULL需要代码kernel：git://git.freescale.com/imx/uboot-imx.git​ branch：imx_4.1.15_2.0.0_ga（最新的是imx_4.9.11_1.0.0_ga）uboot：git://git.freescale.com/imx/uboot-imx.git​ branch：imx_v2016.03_4.1.15_2.0.0_ga（最新的是imx_v2017.03_4.9.11_1.0.0_ga） 工具链获取自己搭建编译工程需要单独下载工具链，可以从linaro官网下载，根据需求选择正确的工具链 编译&amp;移植uboot编译&amp;移植 官方代码提供了几多板型支持，根据实际情况选择最接近的一个，拷贝一份（有多个文件），命名为hd_mx6ull_ddr3 在uboot根目录下执行make hd_mx6ull_ddr3_defconfig生成原始配置； 根据实际硬件及需求进行调试代码； 将编译生成-boot.imx文件拷贝到目标位置； 注：编译前需要配置好工具链 kernel编译&amp;移植 官方代码提供了几多板型支持，根据实际情况选择最接近的一个拷贝命令名为imx6ull-14x14-hd.dts，同时添加对imx6ull-14x14-hd.dts的编译控制； 在kernel根目录下执行make ARCH=arm imx_v7_defconfig生成原始配置； 执行make menuconfig，根据实现硬件及需求进行配置； 根据实际硬件及需求进行调试代码； 将编译生成的zImage和imx6ull-14x14-hd.dtb 文件拷贝到目标位置； 注：编译前需要配置好工具链和ARCH rootfs编译可以使用ubuntu core作为文件系统，直接从ubuntu 官网下载，然后再根据具体需求进行增减功能 ububtu core可以从官网下载：http://old-releases.ubuntu.com/releases/ubuntu-core/releases CPU超频方法 设备树operating-points CPU可工作的频率由设备树的operating-points决定，目前的设备树 12345678operating-points = &lt; /* kHz uV */ 996000 1275000 792000 1225000 528000 1175000 396000 1025000 198000 950000&gt;; 从设备树来看，没有做限制（当然也可以自己修改来限制最高运行频率，不过应该没人这么干）既然设备树里没有限制，那就应该是代码中识别了CPU的型号，取消了其中某些选项 查找代码 最终定位到mach-imx6ull.c文件 123456789101112131415161718192021222324252627282930313233343536static void __init imx6ul_opp_check_speed_grading(struct device *cpu_dev)&#123; …… /* * Speed GRADING[1:0] defines the max speed of ARM: * 2b'00: Reserved; * 2b'01: 528000000Hz; * 2b'10: 700000000Hz(i.MX6UL), 800000000Hz(i.MX6ULL); * 2b'11: Reserved(i.MX6UL), 1GHz(i.MX6ULL); * We need to set the max speed of ARM according to fuse map. */ val = readl_relaxed(base + OCOTP_CFG3); val &gt;&gt;= OCOTP_CFG3_SPEED_SHIFT; val &amp;= 0x3; if (cpu_is_imx6ul()) &#123; if (val &lt; OCOTP_CFG3_SPEED_696MHZ) &#123; if (dev_pm_opp_disable(cpu_dev, 696000000)) pr_warn(\"Failed to disable 696MHz OPP\\n\"); &#125; &#125; if (cpu_is_imx6ull()) &#123; if (val != OCOTP_CFG3_SPEED_1_GHZ) &#123; //将这几行屏蔽可超频到996Mhz if (dev_pm_opp_disable(cpu_dev, 996000000)) pr_warn(\"Failed to disable 996MHz OPP\\n\"); &#125; if (val != OCOTP_CFG3_SPEED_696MHZ) &#123; //将这几行屏蔽可超频到792Mhz if (dev_pm_opp_disable(cpu_dev, 792000000)) pr_warn(\"Failed to disable 792MHz OPP\\n\"); &#125; &#125; iounmap(base);put_node: of_node_put(np);&#125; 通过分析代码可知，读取OCOTP_CFG3寄存器来判断是否要屏蔽掉某些工作频率，datasheet中关于OCOTP_CFG3的描述 注：提升主频相应的VDD_SOC_IN也要提升，否则可能不稳定 实测 目前开发板使用的CPU标称频率是528Mhz，通过修改代码超频到792Mhz，进行对比测试（使用浮点运行、双精度浮点运算、整形运行3种模式运行对比测试）： 从5128Hhz超频到792Mhz，CPU计算性能提升50%，主频提升成正比关系 几点说明： 12341. 超频后CPU 100%运行，CPU温度没有明显变化（手摸没有明显发热）；2. 次测试在开发板上执行，超频后没有做稳定性挂机测试；3. 发板上VDD_SOC_IN电压只有1.2V，理论上是不够的，但测试时没发现问题；4. 代码中792Mhz对应的ARM电压是1.225V，因为VDD_SOC_IN不够，实测只有1.19V； 内存配置内存配置涉及到以下3部分： 内存配置参数 内存参数校准 内存大小自适应 内存配置参数内存参数的配置在uboot/board/freescale/xxx/imximage.cfg (xxx是板子名，目前是hd_mx6ull_ddr3) 1234567891011121314...DATA 4 0x020c4068 0xffffffffDATA 4 0x020c406c 0xffffffffDATA 4 0x020c4070 0xffffffffDATA 4 0x020c4074 0xffffffffDATA 4 0x020c4078 0xffffffffDATA 4 0x020c407c 0xffffffffDATA 4 0x020c4080 0xffffffffDATA 4 0x020E04B4 0x000C0000DATA 4 0x020E04AC 0x00000000DATA 4 0x020E027C 0x00000030DATA 4 0x020E0250 0x00000030... 这些东西，是什么意思呢？不在这里讲，这里只讲这些数据怎么得到 下载DDR配置脚本文件（1个excel文件），点击这里下载，也可以进入NXP的官方社区搜索下载 根据实际使用的内存参数（需要查看内存芯片手册）进行配置，详细的说明文档点击这里可以下载 将excel文件中的RealView.inc表格里的文件复位出来，创建一个文本文件（文件名随便取，后缀为inc，比如取名：imx6ull_hd_ddr3.inc），到此，已经得到一份基础的配置文件，不过如下图所示，基础配置文件中有几项红色的需要校准 内存参数校准内存参数校准目的：摘自官网论坛 It performs write leveling, DQS gating, read/write delay calibration on the target board to match the layout of the board and archive the best DDR performance. 说明校准与PCB设计相关 修改基础的配置文件，将Disable WDOG屏蔽，具体修改如下 12345wait = on //============================================================================= // Disable WDOG //============================================================================= //setmem /16 0x020bc000 = 0x30 //将一行屏蔽 修改原因（官网论坛有描述） Q. I see an error message that states “ERROR: DCD addr is out of valid range.”, why is this and how do I resolve? A. Sometimes, when using the register programming aid, there are registers writes that are not supported in the DCD range. Try looking for the following items and comment them out from the DDR initialization script:wait = onsetmem /16 0x020bc000 = 0x30 // disable watchdog (note the address for this may be different between i.MX6x devices) 根据实际的硬件校准参数，需要下载校准工具，目前最新版本2.7.0，点击这里下载注意：使用该工具时，需要将设备切换到Serial Download模式 经过一段时间的校准后会生成校准数据，将校准参数写入到基础配置文件 重新加载配置文件，进行压力测试，如果测试成功则可以将配置文件导入到uboot里导入方法：手工对照一个一个复制，也可以用编辑工具编辑好再复制，总之只能手工 内存大小自适应前面讲的内存参数配置里包含了大小，但这个大小只涉及内存控制器，相应的参数会填充到内存控制器里。imx6的默认uboot代码，识别内存大小的方法是直接从控制器里读取配置，如果设备的内存大小是固定的，不同大小的内存对应不同的软件版本，这种方法是可行啊，但是… 我们希望一个软件版本能适应不同内存大小，这要怎么做呢？ 首先要确认设备需要使用的最大内存是多少，内存大小参数按照最大的来填写 uboot代码里使用uboot官方的做法，使用get_ram_size去获取内存大小 kernel设备树里的内存配置，使用最大值 原理说明（感兴趣的可以阅读）： 写入到内存控制器的参数(片选、bank数、位宽、行列地址等)会控制内存访问时发出正确的读写时序，细节可查看CPU datasheet； 不同容量同类型的DDR，一般只有行地址（Row Address）不同（有兴趣的可以看DDR手册），其他参数是一致的； CPU访问内存时，imx6有2种地址映射方法（从高地址到低地址）： BANK-ROW-COL（bank interleaving off） ROW-BANK-COL（bank interleaving on）详情可查看CPU datasheet 当bank interleaving on里，行地址(ROW)被映射到最高位，访问高地址和低地址对就的时序是一样的 从原理可以看出，内存大小自适应是有前提的： 打开bank interleaving，在MMDC_MDMISC寄存器中（官方默认配置是打开的） 需要使用相同类型的内存：位宽bank数、列地址大小、页大小相同，关键的时序参数也要相同 uboot下硬件接口适配官方默认uboot代码可以驱动串口、网口、USB、TF卡、I2C等，在新的硬件下，这些接口需要重新进行适配 串口适配 每1步：需要正确配置串口引脚，由setup_iomux_uart函数完成 1234static void setup_iomux_uart(void)&#123; imx_iomux_v3_setup_multiple_pads(uart1_pads, ARRAY_SIZE(uart1_pads));&#125; 1234static iomux_v3_cfg_t const uart1_pads[] = &#123; MX6_PAD_UART1_TX_DATA__UART1_DCE_TX | MUX_PAD_CTRL(UART_PAD_CTRL), MX6_PAD_UART1_RX_DATA__UART1_DCE_RX | MUX_PAD_CTRL(UART_PAD_CTRL),&#125;; 注：请确保使用的引脚配置没有被其他代码重新配置 第2步：配置软件需要使用的串口，在全局配置文件中 12#define CONFIG_MXC_UART#define CONFIG_MXC_UART_BASE UART1_BASE 网口适配 这里说的网口是指CPU自带的网口 第1步：根据硬件设计，确认选择哪个网口（imx6ull最多有2个网口，一般会选择0），在全局配置文件中 第2步：根据硬件设计，确认选择的PHY接口类型（通常会有RMII）以及PHY的设备地址（需要查看PHY芯片手册） 第3步：选择PHY芯片驱动 12345678910111213141516171819202122#ifdef CONFIG_CMD_NET#define CONFIG_CMD_PING#define CONFIG_CMD_DHCP#define CONFIG_CMD_MII#define CONFIG_FEC_MXC#define CONFIG_MII#define CONFIG_FEC_ENET_DEV 0 //选择网口0#if (CONFIG_FEC_ENET_DEV == 0)#define IMX_FEC_BASE ENET_BASE_ADDR#define CONFIG_FEC_MXC_PHYADDR 0x0 //PHY的设备地址#define CONFIG_FEC_XCV_TYPE RMII#elif (CONFIG_FEC_ENET_DEV == 1)#define IMX_FEC_BASE ENET2_BASE_ADDR#define CONFIG_FEC_MXC_PHYADDR 0x1#define CONFIG_FEC_XCV_TYPE RMII#endif#define CONFIG_ETHPRIME \"FEC\" //网口名称，无关紧要#define CONFIG_PHYLIB //表示需要使用外部PHY，相应的驱动代码会编译#define CONFIG_PHY_SMSC //硬件使用的PHY厂家，表示使用SMSC的PHY，相应的SMSC的PHY驱动会被编译#endif 注：如果硬件使用的PHY，uboot代码中没对应的驱动，可以尝试使用通用驱动，即：只定义CONFIG_PHYLIB，一般通用驱动可以用于决大部分硬件的驱动 第4步：硬件引脚复用配置，由setup_iomux_fec函数完成 12345678910111213141516171819static void setup_iomux_fec(int fec_id)&#123; if (fec_id == 0)&#123; imx_iomux_v3_setup_multiple_pads(fec1_pads, ARRAY_SIZE(fec1_pads)); /* Reset the PHY */ gpio_direction_output(IMX_GPIO_NR(5, 9) , 0); mdelay(100); gpio_direction_output(IMX_GPIO_NR(5, 9) , 1); &#125;else &#123; imx_iomux_v3_setup_multiple_pads(fec2_pads, ARRAY_SIZE(fec2_pads)); /* Reset the PHY */ gpio_direction_output(IMX_GPIO_NR(5, 6) , 0); mdelay(100); gpio_direction_output(IMX_GPIO_NR(5, 6) , 1); &#125;&#125; 正确配置fec1_pads(或fec2_pads)即可 注意：setup_iomux_fec包含了PHY复位的控制，相应的GPIO也要配置正确 USB适配 第1步：配置实际使用的USB接口数量 第2步：硬件是否使用OTG功能，使用OTG功能时，需要正确配置ID引脚 1#define CONFIG_USB_MAX_CONTROLLER_COUNT 2 //硬件使用几个USB接口 123static iomux_v3_cfg_t const usb_otg_pads[] = &#123; MX6_PAD_GPIO1_IO00__ANATOP_OTG1_ID | MUX_PAD_CTRL(OTG_ID_PAD_CTRL),&#125;; TF卡适配按照正常的设计i.MX6 ULL的TF卡都会接在USDHC1上，一般不会有什么问题 需要注意一点：官方默认代码有USDHC的复位控制，实际硬件如果不使用复位功能，需要去掉相应的代码 I2C适配uboot下一般不需要使用I2C功能，如果确实需要使用，要进行以下几点适配 确认使用哪路I2C（i.MX6 ULL可提供多路I2C），在主配置文件中 正确配置引脚复用 12#define CONFIG_SYS_I2C_MXC_I2C1 /* enable I2C bus 1 */#define CONFIG_SYS_I2C_MXC_I2C2 /* enable I2C bus 2 */ 123456789101112static struct i2c_pads_info i2c_pad_info1 = &#123; .scl = &#123; .i2c_mode = MX6_PAD_UART4_TX_DATA__I2C1_SCL | PC, .gpio_mode = MX6_PAD_UART4_TX_DATA__GPIO1_IO28 | PC, .gp = IMX_GPIO_NR(1, 28), &#125;, .sda = &#123; .i2c_mode = MX6_PAD_UART4_RX_DATA__I2C1_SDA | PC, .gpio_mode = MX6_PAD_UART4_RX_DATA__GPIO1_IO29 | PC, .gp = IMX_GPIO_NR(1, 29), &#125;,&#125;; I2C引脚配置中有GPIO的配置，作用：I2C初化时会尝试检测总线是否可以正常工作，需要用到GPIO模式 linux系统下接口调试linux系统下的接口调试主要通过配置设备树来完成，设备树需要与代码匹配（设备树中的东西在kernel代码中是有对应的处理流程的） 涉及的内容比较多，这里只做简单描述。 设备树裁剪默认设备树代码中添加了许多设备，需要根据实际的硬件进行裁剪，比如： 123456789101112backlight &#123; compatible = \"pwm-backlight\"; pwms = &lt;&amp;pwm1 0 5000000&gt;; brightness-levels = &lt;0 4 8 16 32 64 128 255&gt;; default-brightness-level = &lt;6&gt;; status = \"disabled\"; //设置成disabled，则不会注册到系统中，但为了代码的简洁性，可以将整个backlight删除&#125;;pxp_v4l2 &#123; compatible = \"fsl,imx6ul-pxp-v4l2\", \"fsl,imx6sx-pxp-v4l2\", \"fsl,imx6sl-pxp-v4l2\"; status = \"disabled\";&#125;; 串口包含2部分 注册串口设计（当然也是修改设备树），比如下面的配置是添加注册2个串口 1234567891011121314&amp;uart1 &#123; pinctrl-names = \"default\"; pinctrl-0 = &lt;&amp;pinctrl_uart1&gt;;//UART1使用的引脚，需要正确设置，从设备树已有代码很容易看出怎么使用 status = \"okay\"; //表示将uart1注册到系统中&#125;;&amp;uart2 &#123; pinctrl-names = \"default\"; pinctrl-0 = &lt;&amp;pinctrl_uart2&gt;;//UART2使用的引脚 fsl,uart-has-rtscts; //打开流控功能 /* for DTE mode, add below change */ /* fsl,dte-mode; */ /* pinctrl-0 = &lt;&amp;pinctrl_uart2dte&gt;; */ status = \"okay\";//表示将uart2注册到系统中&#125;; 指定系统使用哪个串口作为标准输出口（输出kernel打印） 123chosen &#123; stdout-path = &amp;uart1;&#125;; ​ 网口驱动 网口驱动主要是在PHY的适配上，细节如下： 看设备树中，默认代码将mdio总线注册在fec2（总共有fec1和fec2），不合常理，一般应该注册在第一个（fec1）； 阅读代码，代码设计将mdio注册在eth0上，代码中按照probe顺序注册网口，因为在设备树中fec2在fec1前面，因此fec2注册成eth0，fec1注册成eth1 为方便常理认知，以及后续单网口与双网口兼容，将fec1放在fec2前面 针对Y2系统，支持2个网口，但只有一个MDIO总线引脚，如果需要使用Y2的双网口功能，需要软件特别处理，官方代码设计已经有处理，但需要做简单修改，原因及修改如下： 硬件设计中phy的时钟由CPU提供； MDIO总线只能注册在第1个网口上（比如注册在fec1上） 初始化fec1时，fec2没有打开，对应的phy没有时钟，因此不能自动探测到phy型号； 设备树中需要指定fec2的phy ID 修改示例： 1234567891011121314mdio &#123; #address-cells = &lt;1&gt;; #size-cells = &lt;0&gt;; ethphy0: ethernet-phy@0 &#123; compatible = &quot;ethernet-phy-ieee802.3-c22&quot;; reg = &lt;0&gt;; &#125;; ethphy1: ethernet-phy@1 &#123; compatible = &quot;ethernet-phy-id0007.c0f1&quot;; reg = &lt;1&gt;; &#125;;&#125;; SD/EMMC驱动默认代码运行时，sd插入会有错误打印 12mmc0: tuning execution failedmmc0: error -5 whilst initialising SD card 需要修改设备树，添加“no-1-8-v”属性 USB123456789101112131415161718192021&amp;usbotg1 &#123; dr_mode = \"otg\"; //注意模式选择 srp-disable; //OTG模式里需要这些选项 hnp-disable; adp-disable; status = \"okay\";&#125;;&amp;usbotg2 &#123; dr_mode = \"host\"; disable-over-current; //关闭过流检测，硬件一般不设计这个功能，如果硬件设计了，则需要正配置 status = \"okay\";&#125;;&amp;usbphy1 &#123; tx-d-cal = &lt;0x5&gt;;//D_CAL，用于补偿电路USB电流的损耗，值越大补偿越多&#125;;&amp;usbphy2 &#123; tx-d-cal = &lt;0x5&gt;;&#125;;","categories":[{"name":"芯片方案","slug":"芯片方案","permalink":"http://wzhchen/github.io/categories/芯片方案/"}],"tags":[{"name":"imx6","slug":"imx6","permalink":"http://wzhchen/github.io/tags/imx6/"}],"keywords":[{"name":"芯片方案","slug":"芯片方案","permalink":"http://wzhchen/github.io/categories/芯片方案/"}]},{"title":"i.MX 6ULL研究笔记_硬件篇","slug":"芯片方案/imx6/imx6ull方案研究_硬件篇","date":"2018-01-16T16:00:00.000Z","updated":"2019-01-14T07:51:08.966Z","comments":true,"path":"芯片方案/imx6/imx6ull方案研究_硬件篇/","link":"","permalink":"http://wzhchen/github.io/芯片方案/imx6/imx6ull方案研究_硬件篇/","excerpt":"主篇文章主要记录imx6的研究过程，将工作中有的到的重要部分提炼出来，主要描述与硬件相关的内容，也会涉及到一部分底层软件。 相关文章：i.MX 6ULL研究笔记_软件篇","text":"主篇文章主要记录imx6的研究过程，将工作中有的到的重要部分提炼出来，主要描述与硬件相关的内容，也会涉及到一部分底层软件。 相关文章：i.MX 6ULL研究笔记_软件篇 i.MX 6ULL分类i.MX 6ULL有几大系列（Y0,Y1,Y2,Y7）,各系列接口资源不一样，各系列还可以根据主频不同再细分，另外还有工业级和消费级之分 Y0系列：基础系列，只有528Mhz 一种主频，有工业级和消费级 Y1系列：比Y0多1个USB，添加1个CAN Y2系列：接口丰富，主频可选，相应的价格也比较贵 Y7系列：增加电子墨水屏接口，没有工业级 Ethernet USB 工业级 消费级 CAN EPDC LCD/CSI Y0@528Mhz 1 1 √ √ - - - Y1@528Mhz 1 2 √ √ 1 - - Y2@528Mhz 2 2 √ √ 2 - 1 Y2@792Mhz 2 2 √ - 1 Y2@900Mhz 2 2 √ - 1 Y7@528Mhz 1 2 √ - 1 1 Y7@900Mhz 1 2 √ - 1 1 其他常用接口（UART、I2C、SPI、PWM）各系列都有，满足常规应用，特殊需求需要查看手册 i.MX 6ULL核心电压设计i.MX6中ARM的核心有2个：VDD_ARM_CAP 和 VDD_SOC_CAP，这两个都是由VDD_SOC_IN经过LDO产生，如下图所示： 不同的工作主频，需要的VDD_ARM_CAP电压不同，频率越高需要的电压越高，手册中描述，为保证LDO的正常工作，需要满足VDD_SOC_IN比VDD_ARM_CAP高125mV 官方的代码中的对应关系，如下所示 主频(kHz) VDD_ARM_CAP电压(uV) 对应的VDD_SOC_IN 996000 1275000 1.4 V 792000 1225000 1.35 V 528000 1175000 1.3 V 396000 1025000 1.15 V 198000 950000 1.075 V 因此需要根据CPU运行的主频选择合适的VDD_SOC_IN电压，比如希望CPU能运行在792Mhz，则外部的VDD_SOC_IN需要1.35V，当然如果能够通过软件动态调试VDD_SOC_IN的电压就最好的，官方的硬件设计可以支持动态调试电压，具体可以参考官方DEMO板的原理图。 还有另外一个方案，如果CPU只运行在528Mhz频率及以下，可以关闭LDO功能，则VDD_SOC_IN可以设计更低的电压1.175V（手册描述最低1.15V） 支持的内存CPU可以支持以下3种内存 Parameter DDR3 DDR3L LDDDR2 Clock frequency 400 MHz 400 MHz 400 MHz Bus width 16-bit 16-bit 16-bit Channel Single Single Single Chip selects 2 2 2 可支持的内容颗粒密度（256 Mbits–8 Gbits） 总共最大可支持2GB内存 内存的参数配置存放在uboot头里，后续会讲到 CPU超频为什么研究超频，如果最便宜的在Y0系列接口满足要求，但主频（或者说性能）不满足要求时也可尝试提高CPU主频，当然这个要经过长时间的测试来检测其稳定性。 官方没有提供超频的用法及相关的测试数据，但手册中有如下描述 PLL1 (also referred to as ARM_PLL) - This is the PLL clocking the ARM core complex. It is a programmable integer frequency multiplier capable of output frequency of up to 1.3 GHz. Note that this frequency is higher than the maximum chip supported frequency 1.0 GHz CPU的核心频率由PLL1控制，可以通过修改PLL1的参数修改核心频率，从手册上来看是可以超频的。 测试也是可以的，具体方法不在这里描述。 eFUSEeFUSE是一块配置区域，使用熔丝技术，即只能配置一次（每个bit只能由0写成1） eFUSE的总大小为256字节：8个bank 8个word * 4个bytes，其中大部分已经被厂家定义了其使用目的，比如启动配置、网口MAC地址等，目前有44 bytes可用于通用目的。 可根据具体业务来决定是否使用这块区域 引脚规划引脚选择主要考虑向后兼容性，保留LCD引脚 GPIO选择CPU的绝大部分引脚可用于GPIO功能，但为便于向后兼容，应优先考虑使用SNVS_TAMPERx，这里有10个可用的GPIO（SNVS_TAMPER默认是GPIO功能） 如果还是不够用，可以考虑从CSI引脚中选取（工业产品使用CSI的可能性比较小）​ CSI_DATA04 ~ CSI_DATA07计划用一SPIGPIO1_IO0x 中有部分已经用于其他功能，可以使用的GPIO已经不多 GPIO1_IO00、GPIO1_IO05：OTG_ID（不使用时要拉低） GPIO1_IO02 ~ GPIO1_IO03：I2C1 GPIO1_IO06 ~ GPIO1_IO07：MDIO GPIO1_IO08 ~ GPIO1_IO09：PWM WDOGWatchdog有一个非常有用的功能，输出复位信号，可以用于控制设备重新上电，推荐使用LCD_RESET引脚 串口Y0系列最多4个串口，Y1、Y2系列最多8个串口，使用注意事项： 尽量使用UART1 ~ UART5，有专门的引脚，不容易与其他功能产生引脚冲突，其中UART1 ~ UART3有专门的流控引脚 调试串口尽量选择UART1官方代码默认使用UART1，有可能后期需要使用官方的DEMO程序做对比测试 使用485功能时，尽量选择UART2UART1 ~ UART3有专门的引脚可用于收、发切换UART1用于调试串口UART3的收、发切换会复用成CAN CANY0系列没有CAN，Y1系列有1路CAN，Y2系列有2中CAN CPU设计时没给CAN专用的引脚，需要从其他引脚复用，推荐的复用方法：CAN1：UART3_CTS、UART3_RTSCAN2：UART2_CTS、UART2_RTS（UART2的CTS/RTS可选择UART3RX/TX引脚，不使用UART3） 使用2路CAN的可能性不大，如果确实要使用，则牺牲UART3接口 I2CCPU支持多路I2C，一般的硬件用2路就足够了， 建议使用：I2C1：GPIO1_IO2、GPIO1_IO3I2C2：UART5_TX_DATA、UART5_RX_DATA SPICPU支持多路SPI，一般的硬件用1路就足够了， 建议使用：ECSPI1：​ MISO：CSI_DATA07​ MOSI：CSI_DATA06​ SCLK： CSI_DATA04​ CS： CSI_DATA05 SAISAI是串行音频接口，建议将其引出来，可以使用JTAG引脚来复用 注：作音频功能时，同时需要用到I2C接口 PWMCPU支持多路PWM，一般不需要使用，暂时保留2个PWM1：GPIO1_IO08PWM2：GPIO1_IO09 系统启动内部ROM CPU复位后从内部（on-chip）ROM开始运行，内部ROM几个主要功能： 可以从多种不同外设加载启动程序进行启动； 支持USB/UART升级 DCD配置（用于内存初始化，后续会讲到） 执行加密的boot（目前没有使用） 唤醒设备（目前没有使用） 支持的外部存储设备类型 NOR flash NAND flash OneNAND flash SD/MMC（注：可支持3.3V和1.8V，但也有使用前提） SPI NOR flash 或者 EEPROM QSPI flssh 内部ROM运行的具体流程图可以参考datasheet 启动模式配置启动模式由BOOT_MODE和GPIO（或eFUSE）决定，批量使用时，一般使用GPIO，而不使用eFUSE 具体的启动模式如下图所示： 其中红色部分为选择的配置建议硬件预留或其他办法，保证后续可以使用Serial Download模式（USB下载模式，设备作为从模式连接PC），可用于内存校准身等硬件调试 具体细节也请查看datasheet 8.2.1 Boot mode pin settings 8.5 Boot devices (internal boot) 8.5.3.1 Expansion device eFUSE configuration IVT头CPU启动时，内部ROM从指定的外部存储器中读取一段数据用于初始化，该数据需要包含一定的格式，称之为IVT（Image Vector Table ）； 内部ROM从eMMC的0x400（1KB）位置读取IVT，读取大小4kB； 标准u-boot编译成生的文件是u-boot.bin，imx6的u-boot编译会把IVT头放在uboot.bin文件最前面，大小为3KB，生成u-boot.imx文件； 将u-boot.imx烧录到eMMC时需要偏移1KB进行烧录 如此设计原因：eMMC最前面512 bytes可用于MBR，方便eMMC的分区操作，然后再预留512 bytes DCD数据IVT头中最重要的一部分数据是DCD（Device Configuration Data），DCD有什么作用呢？ 在CPU复位后，所有的寄存器都保持在默认的状态，内部ROM启动后会做一些基础的必要配置，但这些配置远远不够，因为内部ROM不知道最终的硬件形态，无法做外设的初始化，特别是内存的初始化，因此内部ROM执行初始化时需要从外部导入一些配置项进行，这些配置项就是DCD数据。 DCD数据的格式： Header： Tag+ Length+ Version，其中Length表示有多少个配置需要执行 [CMD]：具体的配置命令： Address(4 bytes) + Value(4 bytes)，意思是，向Address写入Value [CMD]：同上 … DCD的数据在u-boot中，路径：board/freescale/xxx/imximage.cfg (xxx是板子名，目前是hd_mx6ull_ddr3) 通过eMMC启动背景知识介绍配置eMMC启动，需要了解这些背景知识 eMMC中包含2个boot分区+1个用户分区（硬件分区，与平时的软件分区概念不一样），可以选择其中一个存放boot程序，新eMMC会有更多的分区，这些可以在Linux的启动打印中看到； eMMC中有几个重要的配置寄存器（掉电不丢失），用于配置是否使用boot分区、当前使用哪个分区等； CPU启动时可以配置成从eMMC的boot分区加载boot程序； eMMC的每一个硬件分区都是独立编址的，所以在访问前要先指定访问哪一个分区； eMMC boot相关寄存器PARTITION_CONFIG Bit 7 Bit 6 Bit [5:3] Bit [2:0] Reserved BOOT_ACK BOOT_PARTITION_ENABLE PARTITION_ACCESS BOOT_ACK：CPU加载boot程序时是否使用ACK，需要与CPU端的配置保持一致 BOOT_PARTTION_ENABLE：是否使用boot功能，使用哪个分区存放boot程序，一般选择boot1分区 PARTTION_ACCESS：当前访问的是哪个分区，烧录boot时需要将其他指定到正确的分区，一般是boot1分区，烧录完成后需要改成0（正常模式） BOOT_BUS_WIDTH Bit [7:5] Bit [4:3] Bit 2 Bit [1:0] Reserved BOOT_MODE RESET_BOOT_BUS_WIDTH BOOT_BUS_WIDTH BOOT_MODE：读取boot程序的工作模式，需要与CPU端保持兼容 RESET_BOOT_BUS_WIDTH：未知 BOOT_BUS_WIDTH：读取boot程序的数据宽度，需要与CPU端保持一致 0：1bit, 1:4bit, 2:8bit boot_mode说明： 硬件引脚为保证eMMC能正常启动，且后续能通过TF卡来升级，使用USDHC1接TF卡（可用于生产烧录），使用USDHC2接eMMC，具体的引脚如下连接如下： Signal USDHC1 USDHC2 备注 CLK SD1_CLK NAND_RE_B.alt1 CMD SD1_CMD NAND_WE_B.alt1 DATA0 SD1_DATA0 NAND_DATA00.alt1 DATA1 SD1_DATA1 NAND_DATA01.alt1 DATA2 SD1_DATA2 NAND_DATA02.alt1 DATA3 SD1_DATA3 NAND_DATA03 DATA4 NAND_DATA04 USDHC1接TF卡，不需要DATA4-7 DATA5 NAND_DATA05 DATA6 NAND_DATA06 DATA7 NAND_DATA07 VSELECT GPIO1_IO05 GPIO1_IO08 使用固定电压3.3V，可以不接 RESET_B GPIO1_IO09 NAND_ALE 不使用reset功能，可以不接 CD_B UART1_RTS_B — TF烧录时需要使用CD脚 TF卡烧录原理当配置的启动设备(eMMC)无法启动时，会从uSDHC1(硬件接TF卡)启动 When the internal boot and recover boot (if enabled) failed, the SDMMC_MFG_DISABLE fuse bit isn’t set and the EEPROM recovery fuse bit is set, the boot goes to the SD/MMC manufacture mode before the serial download mode. In the manufacture mode, one bit bus width is used despite of the fuse setting. In the manufacture mode, the SD or MMC card will be scanned on the uSDHC1. If a card is detected and a valid boot image is found in the card, the boot image is loaded and executed. Pad of SD1_CD is used to detect whether a card is inserted or not 因此SD1_CD一定要接，另外manufacture mode默认是打开的 看门狗CPU内部有一个看门狗，看门狗的作用就不多说了，这里主要讲一下CPU自的看门狗特点： 看门狗的周期0.5s ~ 128s，相比硬件看门狗固定的周期（很小），使用起来更方便 看门狗事件产生之前可以触发中断，通过中断程序可以检测系统的一些状态 看门狗可以产生一个复位信号出来(复位信号的时间可配置) 通过合理的硬件设计，可以通过硬件看门狗给设备重新上电，实现硬复位功能，可参考imx6ull的DEMO设计 USBi.MX 6ULL最多可支持2个USB接口，均为OTG接口 如果需要使用OTG功能，则需要正确使用OTG_ID引脚 如果只使用host模式，可将OTG_ID引脚拉低，不要将OTG_ID引脚用于其他功能，便于软件做兼容处理 imx6 中USB phy有一个驱动器电流补偿功能，可以通过配置来设置补偿大小，如果USB不稳定可以信尝试修改补偿值 SNVS&amp;实时时钟SNVS(Secure Non-Volatile Storage)，对于常规应用，有以下几个功能： 一个实时时钟计数器 一个通用功能寄存器（非易失的，在SNVS_LP中） 开关机管理（自动&amp;手动） SNVS内部包含2部分： SNVS_HP（高功耗部分，由主电源供电） SNVS_LP（低功耗部分，主电源存在时由主电源供电，主电源不存在时由纽扣电池供电） 从图可看出，ARM核心只与SNVS_HP通讯，读取SNVS_LP寄存器时需要通过SNVS_HP 手册中描述SNVS的典型工作电流是25uA，需要实际测试，可尝试关闭一部分功能看是否会更低","categories":[{"name":"芯片方案","slug":"芯片方案","permalink":"http://wzhchen/github.io/categories/芯片方案/"}],"tags":[{"name":"imx6","slug":"imx6","permalink":"http://wzhchen/github.io/tags/imx6/"}],"keywords":[{"name":"芯片方案","slug":"芯片方案","permalink":"http://wzhchen/github.io/categories/芯片方案/"}]},{"title":"uboot下开启ARMv8的定时器中断","slug":"uboot/uboot下开启ARMv8的定时器中断","date":"2018-01-16T02:13:03.000Z","updated":"2018-03-22T05:38:49.000Z","comments":true,"path":"uboot/uboot下开启ARMv8的定时器中断/","link":"","permalink":"http://wzhchen/github.io/uboot/uboot下开启ARMv8的定时器中断/","excerpt":"在工作需求，需要在uboot下实现一个定时器来完成一些业务，使用的是Cortex A53 CPU（基于ARM v8-A架构），因此对ARMv8-A的定时器以及中断作了一些研究，这篇文章主要描述如在uboot下开启ARM v8的定时器中断。","text":"在工作需求，需要在uboot下实现一个定时器来完成一些业务，使用的是Cortex A53 CPU（基于ARM v8-A架构），因此对ARMv8-A的定时器以及中断作了一些研究，这篇文章主要描述如在uboot下开启ARM v8的定时器中断。 文章内容会涉及到GIC及ARM v8-A(后面简写成ARMv8)架构相关知识，可查看下面2篇文章 、ARM v8架构 注：本文中所使用和参考的uboot版本：U-Boot 2015.07 总体思路一般情况下uboot都是关闭中断的，所以要让定时器正常工作，需要完成以下几点： 打开ARM核心中断，这里主要是指IRQ中断 正确配置中断向量表，中断现场保存与恢复 正确配置GIC 正确配置定时器参数 编写好正确的中断服务函数 打开ARMv8中断这一节描述如何打开ARMv8的IRQ中断，有兴趣的可以自行阅读ARMv8体系结构手册，可以从这里下载。 首先ARMv8运行在64位模式时与ARMv7有很大的区别，不能简单的通过修改CPSR寄存器来完成。 设置DAIF寄存器，打开IRQ中断64位模式下DAIF寄存器定义如下，其实DAIF寄存器只是将ARMv7中CPSR寄存器的A、I、F单独拿出来使用 只需要将I位清空成0即可打开 IRQ 中断针对DAIF寄存器，体系结构中提供了2个位操作寄存器DAIFSet、DAIFClr打开中断代码 123456void enable_interrupts(void)&#123; //开启IRQ asm volatile(\"msr daifclr, #2\"); return;&#125; 相应的关闭中断代码 123456int disable_interrupts(void)&#123; //关闭IRQ asm volatile(\"msr daifset, #2\"); return 0;&#125; 配置中断路由 中断部分，ARMv8与ARMv7最大的不同可能是中断路由了，因为ARMv8中取消了工作模式改用异常级别，因为中断可以通过配置被路由到不同的级别，比如一个中断发生后，可以进入EL1级别处理，也可以进入EL2级别处理。 目前工作使用的软硬件方向中，uboot启动后CPU运行中EL2级别（不确定其他硬件方向运行的级别），使用最小化修改代码框架原则，不修改uboot的运行级别，通过配置将相应的中断路由到EL2级别处理。 下图是我这次选择的中断路由配置，目前使用的硬件方案(A53)实现了EL2和EL3 其中HCR_EL2寄存器的默认值与上图的配置不一致，IMO默认是0，需要修改成1当然其他方案的寄存器可能不同，需要根据实际情况修改修改代码如下 12345678910111213int interrupt_init(void)&#123; unsigned long value, cur_el; /*如果当前处于EL2级别，需要设置HCR_EL2寄存器，将IRQ路由到EL2*/ asm volatile(\"mrs %0, CurrentEL\" : \"=r\" (cur_el)); if(cur_el == 0x8) &#123; asm volatile(\"mrs %0, HCR_EL2\" : \"=r\" (value)); value |= (1&lt;&lt;4); asm volatile(\"msr HCR_EL2, %0\" : : \"r\" (value)); &#125; return 0;&#125; 中断向量表U-Boot 2015.07官方代码中已经正确配置了中断向量表，可以不用太关注。 ARMv8的中断向量表也ARMv7也有很大的区别，v7的中断向量表只有一个并且在固定位置。v8的不同异常级别对应不同的中断向量表，当然可以只实现一个异常级别的中断，比如linux kernel只使用EL1。 ARMv8的中断向量表由VBAR_ELx（x=1,2,3）决定，比如我此次使用的EL2级别，需要配置vbar_el2 因为官方代码已经实现，可以直接查看uboot源码，这里不再详解。 中断现场保护与恢复与中断现场相关的寄存器ELR_ELx（x=1,2,3，下同）：进入ELx异常时保存需要返回的地址，功能ARMv7的LR寄存器类似 SP、SP_ELx：各级别所使用的栈指针，其中SP是当前模式下的栈指针，可以通过SPSel来选择（所有级别都使用SP_EL0、不同级别使用相应的SP_ELx） SPSR_ELx：进入ELx异常时保存处理器的状态，异常返回时会自动恢复到相应的状态寄存器中，正常的中断程序可以不用处理 中断现场保护将所有通用寄存器(x0-x30)和程序返回寄存器(ELR_ELx)入栈，入栈完成后即可进入中断处理流程 因为官方代码已经实现了入栈功能，可以直接查看uboot源码，这里不再详解。 中断现场恢复相应的需要将通用寄存器(x0-x30)和程序返回寄存器(ELR_ELx)出栈，然后使用eret指令返回 代码如下 123456789101112131415161718192021222324252627.macro exception_exit ldp x2, x0, [sp], #16 switch_el x11, 3f, 2f, 1f3: msr elr_el3, x2 b 0f2: msr elr_el2, x2 b 0f1: msr elr_el1, x2 b 0f0: ldp x1, x2, [sp], #16 ldp x3, x4, [sp], #16 ldp x5, x6, [sp], #16 ldp x7, x8, [sp], #16 ldp x9, x10, [sp], #16 ldp x11, x12, [sp], #16 ldp x13, x14, [sp], #16 ldp x15, x16, [sp], #16 ldp x17, x18, [sp], #16 ldp x19, x20, [sp], #16 ldp x21, x22, [sp], #16 ldp x23, x24, [sp], #16 ldp x25, x26, [sp], #16 ldp x27, x28, [sp], #16 ldp x29, x30, [sp], #16 eret.endm 这里再简单说一下eret指令 eret指令的大概作用是：使用当前的SPSR和ELR寄存器，将异常返回，SPSR寄存器的内容会恢复到PSTATE寄存器中，程序从ELR指向的地址继续执行 配置GICGIC是ARM CPU里的中断控制器，对于没有了解过的人来说还是有一点小小的复杂，不过如果只是将ARM核心的定时器中断打开，配置起来还是非常简单的，只需要几个操作： 打开 GIC Distributor总中断 打开CPU核心定时器中断（选择 physical timer，对应的中断是30） 打开GIC CPU interface总中断 12345678910111213141516171819void timer_gic_init(void)&#123; uint32_t value; /*打开GIC Distributor总中断*/ value = readl(GICD_BASE+GICD_CTLR); value |= 1; writel(value, GICD_BASE+GICD_CTLR); /*打开Non-secure physical timer中断，具体可以看GIC-400手册*/ value = readl(GICD_BASE+GICD_ISENABLERn); value |= (1&lt;&lt;30); writel(value, GICD_BASE+GICD_ISENABLERn); /*打开GIC CPU interface总中断*/ value = readl(GICC_BASE+GICC_CTLR); value |= 1; writel(value, GICC_BASE+GICC_CTLR);&#125; 配置定时器参数参考了linux内核，选择physical timer定时器，详细的配置可以查看ARMv8体系结构手册 与定时器相关的寄存器： CNTFRQ_EL0：系统定时器的频率，由硬件决定，软件被始化时需要填写正确的值，目前我使用的是24Mhz CNTP_CTL_EL0, ：定时器使能（包括中断使能）控制 CNTPCT_EL0：定时器计数，只要CPU在运行（没有休眠）就会一直累加，累加的频为CNTFRQ_EL0，不可关闭 CNTP_CVAL_EL0：比较寄存器，如果定时器使能且中断已经打开（由CNTP_CTL_EL0控制），当CNTPCT_EL0计数达到CNTP_CVAL_EL0时，就会产生中断 根据以上几个寄存器的描述可以，只要在CNTP_CVAL_EL0里写入合适的值即可产生想要的中断，具体代码如下： 123456789101112131415161718192021void set_physical_timer(int timeout_ms)&#123; /*定时器使用细节可查看ARMv8体系结构手册*/ unsigned long value, freq, cnt, cmp; /*关闭定时器*/ value = 0; asm volatile(\"msr CNTP_CTL_EL0, %0\" : : \"r\" (value)); /*计算下次超时时间*/ asm volatile(\"mrs %0, CNTFRQ_EL0\" : \"=r\" (freq)); asm volatile(\"mrs %0, CNTPCT_EL0\" : \"=r\" (cnt)); cmp = cnt + (freq/1000)*timeout_ms; asm volatile(\"msr CNTP_CVAL_EL0, %0\" : :\"r\" (cmp)); /*打开定时器*/ value = 1; asm volatile(\"msr CNTP_CTL_EL0, %0\" : : \"r\" (value));&#125; 中断服务函数中断服务函数需要完成几件必要的事情 中断现场保护（前面已经提到） 中断处理 中断现场恢复（前面已经提到） 中断处理分成3个步骤： 从GIC中找出当前的中断编号，对于此次应用，应该是30 重写设置定时器的CNTP_CVAL_EL0寄存器 写GIC的EOI寄存器，指示此次中断处理完毕 具体代码如下 ： 123456789101112void do_irq(struct pt_regs *pt_regs, unsigned int esr)&#123; int irq; irq = readl(GICC_BASE + GICC_IAR); if((irq &amp; 0x3ff) == 30) &#123; set_physical_timer(TIMER_PERIOD); printf(\"%s.%d\\n\", __FUNCTION__, __LINE__); &#125; writel(irq, GICC_BASE + GICC_EOIR);&#125; 1234_do_irq: exception_entry bl do_irq exception_exit","categories":[{"name":"uboot","slug":"uboot","permalink":"http://wzhchen/github.io/categories/uboot/"}],"tags":[{"name":"arm","slug":"arm","permalink":"http://wzhchen/github.io/tags/arm/"},{"name":"uboot","slug":"uboot","permalink":"http://wzhchen/github.io/tags/uboot/"},{"name":"中断","slug":"中断","permalink":"http://wzhchen/github.io/tags/中断/"}],"keywords":[{"name":"uboot","slug":"uboot","permalink":"http://wzhchen/github.io/categories/uboot/"}]},{"title":"ARM v8架构","slug":"ARM架构/arm体系统结构/armV8架构","date":"2018-01-12T02:13:03.000Z","updated":"2019-01-14T07:54:01.536Z","comments":true,"path":"ARM架构/arm体系统结构/armV8架构/","link":"","permalink":"http://wzhchen/github.io/ARM架构/arm体系统结构/armV8架构/","excerpt":"这篇文章主要描述ARM体系结构相关内容，记录工作中用到的头天arm体系结构相关的知识，主要是关于V8-A版本的知识，会不定期的进行更新。","text":"这篇文章主要描述ARM体系结构相关内容，记录工作中用到的头天arm体系结构相关的知识，主要是关于V8-A版本的知识，会不定期的进行更新。 概述ARM体系结构从最初的V1版本到现在已经有很大的变化，总共有8个版本：v1~v8，不过目前正在使用的只有v4 ~ v8，最被的3个版本已经被废弃。 从ARMv7开始，ARM将其体系结构分成3大不同应用，称之为ARM-A、ARM-R、ARM-M A：高性能应用处理器（本文主要描述这种） R：实时操作应用 M：微处理器应用 目前最新的版本是v8，在v7的基础上做了很大的改动： 支持64位工作模式，64位工作模式时称之为AArch64，32位工作模式时称之为AArch32（兼容以前的版本） 取消了CPU的工作模式，采用”异常级别”，有E0~E3 4种级别 异常级别ARM v8的AArch64时取消了ARM v7的工作模式(User/FIQ/IRQ/…)，相应的也取消了CPSR寄存器，改用EL0 - EL3 总共4种异常级别，其中： EL3级别权限最高，EL0级别权限最低 EL0级别为非特权级别，EL1-EL3称为特权级别，通常应用程序在EL0级 通常EL0级用于application，EL1用于kernel，EL2用于Hypervisor或虚拟化，EL3用于安全应用 EL3级别通过SCR_EL3控制EL2-EL0，EL2级别通过HCR_EL2控制EL1-EL0， CPU必须实现EL0,EL1功能，EL2,EL3可以选择性实现，通过ID_AA64PFR0_EL1寄存器可看否实现了EL2及EL3 状态说明 AArch64状态 31个通用的64位寄存器：x0~x30，基中x30通常用于LP寄存器 1个64位PC寄存器 各种系统寄存器，比如SP、SPSR寄存器，每个系统寄存器有多个（异常类型不同），使用_ELx作为后缀 32个128位的SIMD向量 使用armv8的异常模式，有4种异常模式：E0~E3 支持64位虚拟地址总线宽度 有1个PE(处理器)状态寄存器PSTATE 系统寄存器使用添加下标方式来访问不同模式下的寄存器，具体形式：\\&lt;register_name&gt;_ELx 通用定时器ARMv8核心提供了4个定时器 Hypervisor Physical Timer Virtual Timer Physical Timer（linux默认使用这个作为系统时钟） Physical Secure Timer 所有定时器都使用同一个时钟源——系统时钟，一般CNTFRQ_EL0寄存器中会保存定时器的频率 有2个累加寄存器CNTPCT_EL0、CNTVCT_EL0，分别用于Physical 和Virtual定时器，在CPU运行时累加寄存器会一直累加，寄存器是64位的，就算是10Ghz的主频来说可以运行57.4年，理论是够用的 每个定时器有独立的控制寄存器、比较寄存器、计数寄存器 可以通过适当的配置产生想的定时器及中断","categories":[{"name":"ARM架构","slug":"ARM架构","permalink":"http://wzhchen/github.io/categories/ARM架构/"}],"tags":[{"name":"arm","slug":"arm","permalink":"http://wzhchen/github.io/tags/arm/"},{"name":"芯片资料","slug":"芯片资料","permalink":"http://wzhchen/github.io/tags/芯片资料/"}],"keywords":[{"name":"ARM架构","slug":"ARM架构","permalink":"http://wzhchen/github.io/categories/ARM架构/"}]},{"title":"arm中断—GIC硬件","slug":"ARM架构/arm中断控制器/arm中断—GIC硬件","date":"2018-01-09T10:21:46.000Z","updated":"2019-01-14T07:54:54.730Z","comments":true,"path":"ARM架构/arm中断控制器/arm中断—GIC硬件/","link":"","permalink":"http://wzhchen/github.io/ARM架构/arm中断控制器/arm中断—GIC硬件/","excerpt":"本系列将详细描述ARM中断的原理、代码分析和使用实际案例。本文将参考的硬件是GIC-400，Kernel版本 3.10.52","text":"本系列将详细描述ARM中断的原理、代码分析和使用实际案例。本文将参考的硬件是GIC-400，Kernel版本 3.10.52 ARM核中断架构IRQ、FIQ区别FIQ和IRQ是两种不同类型的中断，ARM为了支持这两种不同的中断，提供了对应的叫做FIQ和IRQ处理器模式 两种中断的区别，简单来说就是：FIQ比IRQ快，FIQ会比IRQ快几个指令周期； 对于实时必要求非常高(估计是ns级)的场合可以使用FIQ，相应的代码复杂度也要比较小，否则会失去FIQ的意义 注：在linux系统中，主要是用IRQ，因此代码中有大量的irq字眼，而很少使用fiq ARM核心中断开启&amp;关闭ARMv7框架中，中断的开启与关闭由CPSR（或CPSR_C）寄存器控制，CPSR（或CPSR_C）寄存器需要使用mrs和msr指令来操作，一般只使用汇编代码来控制 IRQ开启：12345678910void enable_interrupts (void)&#123; unsigned long temp; __asm__ __volatile__(\"mrs %0, cpsr\\n\" \"bic %0, %0, #0x80\\n\" \"msr cpsr_c, %0\" : \"=r\" (temp) : : \"memory\");&#125; IRQ/FIQ关闭： 1234567891011int disable_interrupts (void)&#123; unsigned long old,temp; __asm__ __volatile__(\"mrs %0, cpsr\\n\" \"orr %1, %0, #0xc0\\n\" \"msr cpsr_c, %1\" : \"=r\" (old), \"=r\" (temp) : : \"memory\"); return (old &amp; 0x80) == 0;&#125; ARMv8的中断打开方法可以查看下面这篇文章 uboot下开启ARMv8的定时器中断 GIC简介GIC（Generic Interrupt Controller，官网介绍）是ARM公司设计的通用中断控制器，集成在CPU芯片内部，目前有V1~V4版本，从官网可知，目前主要的型号有GIC-400(V2),GIC-500(V3/V4),GIC-600(V3/V4)，其中GIC-400手册可以支持最多8个核心、480个共享中断，GIC-500可以支持最多128个核心、960个共享中断，GIC-600可以支持更多的核心。GIC的作用：简单来说包含2方面 将所有外设的中断统一处理再发送CPU核心，减小CPU核心的复杂度 实现软中断，用于各CPU核心之间通讯 虚拟中断，用于虚拟机 GIC逻辑拆分 上图显示了GIC的内部逻辑框图，大致可以分成4部分：Distributor、CPU interface、GIC virtual interface、virtual CPU interface Distributor block：收集所有中断源进行处理，将优先级最高的中断送给CPU interface处理，主要功能如下 中断使能开关，包含2级开关：全局开关、每个中断对就的开关 设置中断的优先级 设置中断分发给哪个CPU 设置中断的触发属性：边沿触发、电平触发 产生软中断 CPU interface block：决定是否将中断发送给CPU，主要功能如下 控制中断与CPU处理器之间的连线开关，如果关闭了，即使Distributor中使能了中断，中断也不会送达CPU，如果开启，则会将当前优先级最高的中断发送给CPU 设置priority mask(优先级门限)，低于priority mask的中断不被送给CPU 设置优先级策略 中断ACK响应，中断响应后，Distributor会将中断状态设置成Active(或者Active and pending) 中断处理完毕的通知，当中断处理完后，CPU通知CPU interface，表示当前中断处理完成 GIC virtual interface和Virtual CPU interface：用于虚拟机操作，一般用不上，本文不作详细描述 从图中还可以看出，从处理器输入到GIC的中断可以不经过Distributor和 CPU interface，这种模式称之为bypass中断 GIC中断编号&amp;分组GIC v2支持ID0-ID1019，总共1020个中断，不过实际的硬件（比如GIC-400）不会实现这么多 ID0-ID31是私在中断，即每个CPU都对应独立的ID0-ID31 ID32-ID1019 用于SPI（share Peripheral interrupt），这些中断用于CPU的外设，比如GPIO、USB等，共享的意思是各个CPU共享这些中断，即这些中断被所有CPU共享，可以分配给到指定的CPU来处理 ID0-ID15用于SGI（Software-generated interrupt），可以通过写寄存器产生软件中断 ID16-ID31用于PPI（Private Peripheral Interrupt），与SPI相对应，私有的意思是指每个CPU都会对应独立ID16-ID31 GIC设计中，中断分成2个组(group0、group1)，group0里的中断是安全中断，gropu1里的中断是非安全中断，group0的中断可以配置成IRQ或FIQ，goup1的中断是IRQ中断，如果CPU当前处理非安全状态，则读取不到安全中断的状态。 注：目前linux没有使用分组功能，默认都使用group0中断 GIC中断处理状态机 Inactive：没有中断 Pending： 中断已经产生了，等待CPU处理 Active：中断正在被处理，还没结束 Active and pending：中断正在处理，又有新的中断产生 各状态机切换条件： A1/A2：添加 Pending状态 对于SGI，有2种方法：写GICD_SGIR寄存器(产生1个中断)，或者写GICD_SPENDSGIR寄存器(将状态设置成pending) 对于SPI 和PPI，也是2种方法：硬件产生，或者写GICD_ISPENDR寄存器 B1/B2：移除Pending状态 对于SGI，设置GICD_CPENDSGIR寄存器 对于SPI 和 PPI 对于电平触发的中断，电平改变后，Pending状态会移除 对于边沿触发以及写GICD_ISPENDR产生的中断，需要写GICD_ICPENDR寄存器来移除Pendding状态 C：pending到active 相应的中断需要使能 优先级不低于门限值 读GICC_IAR寄存器里发生状态切换 D：pending 到active and pending ​ 当读GICC_IAR寄存器时发生pending条件 E1/E2：移除active ​ 写 GICC_EOIR 或GICC_DIR寄存器 GIC-400硬件介绍 上图显示了GIC-400的框图，从框图可以看出外设与CPU核心不直接相连，外设中断通过GIC通知CPU核心。GIC-400功能： 有16个SGI（通过写GICD_SGIR寄存器产生中断） 每个CPU有6个外部PPI和1个内部虚拟PPI 最多 480个SPI 中断分组功能（通过写 GICD_IGROUPR寄存器来配置） PPI功能分配见下图 ​ 其中28和31是 bypass中断 GIC-400中断优先级： 通过GICD_IPRIORITYR寄存器来配置优先级 安全模式有32个优先级，非安全模式有16个优先级 当有2个或更多相同优先级的中断出现时，编号小的中断优先级较高 寄存器说明GIC寄存器地址：GIC在CPU地址空间的其地址是不固定的，GIC内部的寄存器偏移地址是固定的，因为linux代码中GIC的驱动代码可以做到各平台统一，只需要传递几个(Distributor、CPU interface等)基地址即可 本文主讲Distributor和CPU interfaces寄存器： Distributor寄存器，以GICD_头，偏移地址：0x1000 GICD_CTLR（0x0000）：只有bit[1:0]有用，控制group0、group1的全局开关 GICD_TYPER（0x0004）：只读，查看GIC实现了哪些功能及配置，比如CPU数量、中断线数量等 GICD_IIDR（0x0008）：ID寄存器，只读，GIC-400是0x0200143B GICD_IGROUPRn（0x0080-0x00BC）：中断分组，linux只使用默认值0 GICD_ISENABLERn（0x0100-0x013C）：interrupt Set-Enable，使能中断 GICD_ICENABLERn（0x0180-0x01BC）：Interrupt Clear-Enable ，关闭中断 GICD_ISPENDRn（0x0200-0x023C）：Interrupt Set-Pending ，将中断设置成Pending状态，不适应SGI中断 GICD_SPENDSGIRn（0x0F20-0x0F2C）：SGI Set-Pending，同上，用于SGI中断，每个有8bits，对应8个CPU核心 GICD_ICPENDRn（0x0280-0x02BC）：Interrupt Clear-Pending，移除中断的Pending状态，不适应SGI中断 GICD_CPENDSGIRn（0x0F10-0x0F1C）：SGI Clear-Pending Registers，同上，用于SGI中断 GICD_ISACTIVERn（0x0300-0x033C）：Interrupt Set-Active ，将中断设置成Active状态 GICD_ICACTIVERn（0x0380-0x03BC）：Interrupt Clear-Active，移除中断的Active状态 GICD_IPRIORITYRn（0x0400-0x05FC）：Interrupt Priority，中断优先级设置 ​ 每个中断有8个bits设置，1个寄存器包含4个中断的配置 ​ GIC-400的可用优先级个数是32，只有bit[7:3]有效 ​ linux中全部使用0xA0 GICD_ITARGETSRn（0x0800-0x081C）：Interrupt Processor Targets，设置中断分配给哪个CPU ​ 每个中断有8个bits设置，1个寄存器包含4个中断的配置 ​ 其中前8个寄存器为只读，只会返回当前CPU的值（即每个CPU去读取时返回的值都不一样） ​ 对于SPI中断，Linux默认将其分配给CPU0处理 GICD_ICFGRn（0x0C08-0x0C7C）：Interrupt Configuration，中断配置寄存器，电平触发还是边沿触发 ​ 每个中断有2个bits设置，1个寄存器包含16个中断的配置 ​ GICD_ICFGR0、GICD_ICFGR1用于SGI和PPI，只读 GICD_PPISR（0x0D00）：PPI中断状态寄存器，bit[31:25]有效 GICD_SPISRn（0x0D04-0x0D3C）：SPI中断状态寄存器 GICD_SGIR（0x0F00）：Software Generated Interrupt，写该寄存器产生SGI中断，可以控制往哪个（哪些）CPU发送中断 CPU interfaces寄存器，以GICC_头，偏移地址：0x2000 GICC_CTLR（0x0000）：CPU Interface Control，控制中断是否传给CPU核，控制中断是IRQ还是FIQ GICC_PMR（0x0004）：Priority Mask，控制优先级门限，低于门限的中断不会转发到CPU ​ 设置方法同GICD_IPRIORITYRn ​ linux中使用0xF0 GICC_BPR（0x0008）：Binary Point Register，命名不好，从名字上看不出意思，实际作用是将优先级分成2部分:Group priority 、Subpriority，只使用优先级的Group priority部分，忽略Subpriority部分 ​ 详解：比如GIC-400的默认值是2，则优先级的[7:3]作为Group priority ，[2:0]作为Subpriority，则总共可生成32个优先级，与GICD_IPRIORITYRn保持一致 GICC_IAR（0x000C）：Interrupt Acknowledge，只读，可以查看当前pending的最高优先级中断 GICC_EOIR（0x0010）：End of Interrupt，只写，中断处理完成后需要写该寄存器 GICC_RPR（0x0014）：Running Priority，只读，当前处理中断的优先级 GICC_HPPIR（0x0018）：Highest Priority Pending ，只读，处于Pending状态的中断里优先级最高的 GICC_IIDR（0x00FC）：ID寄存器，GIC-400的值是0x0202143B GICC_DIR（0x1000）：Deactivate Interrupt ，只写，移除中断的Active状态 编程指导使用步骤： 打开ARM核的中断开关，CPSR寄存器 打开Distributor的局开关：GICD_CTLR[0] 打开Distributor的中断开关：寄存器GICD_ISENABLER/GICD_ICENABLER 配置中断触发方式：GICD_ICFGRn 等待中断 读取GICC_IAR寄存器，获取中断编号 执行中断程序 写GICC_EOIR寄存器","categories":[{"name":"ARM架构","slug":"ARM架构","permalink":"http://wzhchen/github.io/categories/ARM架构/"}],"tags":[{"name":"arm","slug":"arm","permalink":"http://wzhchen/github.io/tags/arm/"},{"name":"中断","slug":"中断","permalink":"http://wzhchen/github.io/tags/中断/"},{"name":"芯片资料","slug":"芯片资料","permalink":"http://wzhchen/github.io/tags/芯片资料/"}],"keywords":[{"name":"ARM架构","slug":"ARM架构","permalink":"http://wzhchen/github.io/categories/ARM架构/"}]},{"title":"hexo+github搭建自己的博客","slug":"环境搭建/hexo-github搭建自己的博客","date":"2018-01-08T06:13:34.000Z","updated":"2019-01-14T07:44:04.417Z","comments":true,"path":"环境搭建/hexo-github搭建自己的博客/","link":"","permalink":"http://wzhchen/github.io/环境搭建/hexo-github搭建自己的博客/","excerpt":"从工作到现在也已有多年，积累了不少经验，但基本上没有认真的总结过，时间一长就有许多知识忘记了，到使用时又要去网上找资料学习，最近想着是应该要好好总结一番，一来是为后续工作能直接找自己写的笔记，二来是可以通过这个过程系统性的学习一下需要掌握的知识，如果能有幸帮助到其他人那就是更好了。","text":"从工作到现在也已有多年，积累了不少经验，但基本上没有认真的总结过，时间一长就有许多知识忘记了，到使用时又要去网上找资料学习，最近想着是应该要好好总结一番，一来是为后续工作能直接找自己写的笔记，二来是可以通过这个过程系统性的学习一下需要掌握的知识，如果能有幸帮助到其他人那就是更好了。 基于几上几点因素，所以想建立自己的博客来为后续总结搭建一个平台，但是以前从来没有写过博客的我突然发现搭建一个自己的博客确实要花费不好心思，也要学习一些工具的使用，比如hexo、markdown等，通过几天的学习研究。也基本上弄懂了如何通过hexo和github来搭建自己的博客。为方便后续自己回顾写下了这篇博客来记录搭建过程。 我使用的是Windows系统，以下内部适应于Windows系统。 需要用到的工具及知识 Markdown：Markdown是一种可以使用普通文本编辑器编写的标记语言，通过简单的标记语法，它可以使普通文本内容具有一定的格式。 Typora：个人认为Windows上比较好用的一款Markdown编辑工具。 hexo：快速、简洁且高效的博客框架。点击这里进入官网了解，官网里有详细的使用说明，以及安装教程(包括hexo需要依赖的工具)。 github：是一个面向开源及私有软件项目的托管平台，可以将博客网站部署到gitgub上，使用前需要注册账号（当然是免费的）， git：安装hexo以及部署网站到github都需要使用，点击这里进入官网了解和下载，git命令使用不在些讲述。 hexo安装&amp;使用安装前需要在电脑上建立一个空的目录用于存放博客网站，比如我的存放在e:\\myblog目录。官网上有详细的安装说明，这就不再过多的说明，只做一些补充。 hexo安装补充说明本地安装完hexo后，可以使用“hexo s”命令来查看一下是安装成功，如下图所示： 然后打开浏览器，输入http://loacalhost:4000 ，就可以看到一篇Hello World的文章，表明安装成功，这里如果打不开，有可能是端口被占用，尝试换一个端口号，比如使用”hexo s -p 4001”。 命令行操作官网上的安装教程，好多都是通过命令来执行的，对于没有使用过命令行的人来说，或许会有一点小小的阻力，不想学习命令行操作的可以直接按照教程操作即可。 进入命令模式在博客的根目录下右键，选择“Git Bash Here”,如下图： 使用&amp;优化添加图片一篇优秀的文章少不了几张图片，特别像我现在写的这种环境搭建的文章。hexo官网上的帮助文档已经很清楚的描述了使用方法，点击这里查看。 补充：如果不想通过命令行创建文件，也可以手动创建，同时创建一个同名的资源文件夹 添加”阅读更多”按钮在需要插入按钮的地方编写&lt;!– more –&gt;即可 更换主题如果觉得默认的主题不好看，可以更换主题，可以进入官网下载自己喜欢的主题，我选择的是next主题。 next主题点击这里有详细的教程，包括怎么更换hexo的主题。 补充：博主写这篇博客时，教程里下载路径不是最新的，需要更换下载命令：git clone https://github.com/theme-next/hexo-theme-next themes/next next主题配置个人觉得next的默认主题配置不好像，根据自己的审美做了些配置。配置主是修改修改next目录下的配置文件_config.yml 去掉网页底部的“Hexo 强力驱动”等信息，修改方法：将“powered”、”enable”、“version”设置成false 更换Scheme，改成Pisces 设置个人图像，修改avatar，图像可以放在source/images目录下 打开tags功能 BlueLake主题个人比较喜欢的主题 https://github.com/chaooo/hexo-theme-BlueLake 分类和标签功能分类功能 在命令行下新建一个页面，命令为tags$ hexo new page &quot;categories&quot; 修改刚才新建的tags/index.md文件 ---title: tagsdate: 2018-01-09 13:37:54type: “categories”--- 创建的文章添加tags，比如： categories:- 环境搭建- 杂项 修改next主题的配置文件_config.yml：打开menu-&gt;categories 标签功能 在命令行下新建一个页面，命令为tags$ hexo new page &quot;tags&quot; 修改刚才新建的tags/index.md文件 ---title: tagsdate: 2018-01-08 16:47:35type: “tags”--- 创建的文章添加tags，比如： tags:- 环境搭建 修改next主题的配置文件_config.yml：打开menu-&gt;tags 文章引用hexo的默认通过时间来生成文章路径，引用自己的文章时需要填写时间，如果被引用的文件时间有修改，则引用会失效，可以通过修改permalink来设置文章生成路径的规则 修改hexo 配置文件_config.yml，具体如下 permalink: :title/ 引用方法： 部署到github准备工作 申请github账号直接接入官网申请即可，非常简单 创建一个repository，用于存放博客网站，过程如下图所示： 继续，填写repository的名字，注意：名字格式必须是：github的用户名.github.io 创建完成后请记录记录repository的路径，下一步会用到 创建ssh秘钥，如下命令，创建过程请选择默认值(直接回车3次)，创建完成后会在相应的目录下生成id_rsa和id_rsa.pub文件ssh-keygen -t rsa -C 用户名 将ssh公钥添加到github中，如下图： 继续，选择ssh设置 继续，将id_rsa.pub中的内容填入到key框中 修改hexo配置 hexo中添加自己刚才注册的用户名信息，命令行中输入git config --global user.name 用户名git config --global user.email 邮箱地址 修改hexo的配置文件_config.yml，修改deploy字段，如下所示： deploy:type: gitrepo: git@github.com:wzhchen/wzhchen.github.io.gitbranch: master 注意：冒号后面有一个空格 执行部署使用下面的命令完成部署 hexo deploy 如果hexo deploy提示not found: git，则需要安装一个插件 npm install hexo-deployer-git --save 验证在浏览器里输入”用户名.github.io”即可看到自己搭建的博客了","categories":[{"name":"杂项","slug":"杂项","permalink":"http://wzhchen/github.io/categories/杂项/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://wzhchen/github.io/tags/hexo/"}],"keywords":[{"name":"杂项","slug":"杂项","permalink":"http://wzhchen/github.io/categories/杂项/"}]}]}